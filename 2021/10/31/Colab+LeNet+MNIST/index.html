<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
    
    
        
            
                <link rel="shortcut icon" href="/images/favicon.ico">
            
        
        
            
                <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
            
        
        
            
                <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
            
        
    
    <!-- title -->
    <title>【Colab】基本操作【LeNet】【MNIST】训练测试</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <link href="https://fonts.googleapis.com/css?family=Noto+Sans+SC&display=swap" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/tonsky/FiraCode@2/distr/fira_code.css" rel="stylesheet">
    <!-- rss -->
    
    
        <link rel="alternate" href="/true" title="AXDLMG7&#39;s Blog" type="application/atom+xml"/>
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="max-width mx-auto px3 ltr">

    <div id="header-post">
    <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
    <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
    <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i
                class="fas fa-chevron-up fa-lg"></i></a>
    <span id="menu">
    <span id="nav">
      <ul>
          
              <li><a href="/">首页</a></li>
          
              <li><a href="/archives/">归档</a></li>
          
              <li><a href="/categories/">分类</a></li>
          
              <li><a href="/tags/">标签</a></li>
          
              <li><a href="/about/">关于</a></li>
          
              <li><a href="/search/">搜索</a></li>
          
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
          
              <li><a class="icon" href="/2021/11/01/%E5%86%B3%E8%B5%9B%E8%A7%81/"><i class="fas fa-chevron-left"
                                                                           aria-hidden="true"
                                                                           onmouseover="$('#i-prev').toggle();"
                                                                           onmouseout="$('#i-prev').toggle();"></i></a></li>
          
          
              <li><a class="icon" href="/2021/10/30/10%E6%9C%88%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"><i class="fas fa-chevron-right"
                                                                           aria-hidden="true"
                                                                           onmouseover="$('#i-next').toggle();"
                                                                           onmouseout="$('#i-next').toggle();"></i></a></li>
          
          <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i
                          class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();"
                          onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true"
                                        onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();"
                                        onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
    <li><a class="icon"
           target="_blank" rel="noopener" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/&title=【Colab】基本操作【LeNet】【MNIST】训练测试"><i
                    class="fab fa-qq " aria-hidden="true"></i></a></li>
    <li><a class="icon"
           target="_blank" rel="noopener" href="https://service.weibo.com/share/share.php?url=https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/&title=【Colab】基本操作【LeNet】【MNIST】训练测试"><i
                    class="fab fa-weibo " aria-hidden="true"></i></a></li>
    <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/&text=【Colab】基本操作【LeNet】【MNIST】训练测试"><i
                    class="fab fa-twitter " aria-hidden="true"></i></a></li>
    <li><a class="icon" href="mailto:?subject=【Colab】基本操作【LeNet】【MNIST】训练测试&body=Check out this article: https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/"><i
                    class="fas fa-envelope " aria-hidden="true"></i></a></li>
</ul>
    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">1.介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E6%9F%A5%E7%9C%8B%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">2.</span> <span class="toc-text">2.查看基本配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1%E6%9F%A5%E7%9C%8Bpytorch%E7%89%88%E6%9C%AC"><span class="toc-number">2.0.1.</span> <span class="toc-text">2.1查看pytorch版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8cuda"><span class="toc-number">2.0.2.</span> <span class="toc-text">2.2查看是否可以使用cuda</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E9%85%8D%E7%BD%AE"><span class="toc-number">2.0.3.</span> <span class="toc-text">2.3查看显卡配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E6%8C%82%E8%BD%BD"><span class="toc-number">3.</span> <span class="toc-text">3.挂载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E6%8C%82%E8%BD%BD%E8%B0%B7%E6%AD%8C%E4%BA%91%E7%9B%98"><span class="toc-number">3.0.1.</span> <span class="toc-text">31.挂载谷歌云盘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2%E6%9B%B4%E6%94%B9%E8%BF%90%E8%A1%8C%E7%9B%AE%E5%BD%95"><span class="toc-number">3.0.2.</span> <span class="toc-text">3.2更改运行目录</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E8%AE%AD%E7%BB%83"><span class="toc-number">4.</span> <span class="toc-text">4.训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Reference"><span class="toc-number">5.</span> <span class="toc-text">5.Reference</span></a></li></ol>
    </div>
  </span>
</div>

<div class="content index py4">
    
    <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
        
    <h1 class="posttitle" itemprop="name headline">
        【Colab】基本操作【LeNet】【MNIST】训练测试
    </h1>

        <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">
            AXDLMG7
            
        </span>
      </span>
            
    <div class="postdate">
        
            <time datetime="2021-10-31T12:04:52.457Z"
                  itemprop="datePublished">2021-10-31</time>
            
                (Updated:
                <time datetime="2021-10-31T12:26:33.805Z"
                      itemprop="dateModified">2021-10-31</time>)
            
        
    </div>

            
            
        </div>
    </header>
    
    <div class="content" itemprop="articleBody">
        <p><a target="_blank" rel="noopener" href="https://colab.research.google.com/notebooks/welcome.ipynb">Colab 官网初始界面</a></p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h1><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/zh-cn/cuda-gpus">英伟达官网</a><br>谷歌将原来K80换成了T4<br><img src="https://img-blog.csdnimg.cn/7975074e2ece4cdc8be72e96851fd996.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p>
<h1 id="2-查看基本配置"><a href="#2-查看基本配置" class="headerlink" title="2.查看基本配置"></a>2.查看基本配置</h1><h3 id="2-1查看pytorch版本"><a href="#2-1查看pytorch版本" class="headerlink" title="2.1查看pytorch版本"></a>2.1查看pytorch版本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/b08a271c94da4d0293ac0dbc8ff3cc25.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_13,color_FFFFFF,t_70,g_se,x_16"></p>
<h3 id="2-2查看是否可以使用cuda"><a href="#2-2查看是否可以使用cuda" class="headerlink" title="2.2查看是否可以使用cuda"></a>2.2查看是否可以使用cuda</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/cce0d37208584800922981b38136b11f.png"><br>修改-&gt;笔记本设置-&gt;GPU<br><img src="https://img-blog.csdnimg.cn/38bcb5ea6f724e1a8a120bd71614efcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_19,color_FFFFFF,t_70,g_se,x_16"></p>
<h3 id="2-3查看显卡配置"><a href="#2-3查看显卡配置" class="headerlink" title="2.3查看显卡配置"></a>2.3查看显卡配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line">//注意英文感叹号</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/a222ea06ae0c44ce8f34592494dca1c3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p>
<h1 id="3-挂载"><a href="#3-挂载" class="headerlink" title="3.挂载"></a>3.挂载</h1><h3 id="31-挂载谷歌云盘"><a href="#31-挂载谷歌云盘" class="headerlink" title="31.挂载谷歌云盘"></a>31.挂载谷歌云盘</h3><p>Colab的运行原理实际上就是给你分配一台远程的带GPU的主机，所以它的原始路径不是你的谷歌云盘（也就是你的代码文件）所在的路径。所以第一步我们先要把谷歌云盘挂载带到那台远程主机上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&quot;/content/drive&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>登录谷歌账号并将验证码粘到框中</p>
<h3 id="3-2更改运行目录"><a href="#3-2更改运行目录" class="headerlink" title="3.2更改运行目录"></a>3.2更改运行目录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;/content/drive/MyDrive/Colab Notebooks/LeNet_MNIST_train_test&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>下面是我的目录结构<br><img src="https://img-blog.csdnimg.cn/a96be368c2ef4298af8e0fae94d4f61d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p>
<h1 id="4-训练"><a href="#4-训练" class="headerlink" title="4.训练"></a>4.训练</h1><p>【LeNet】+【MNIST】</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>),</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        output = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">train_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    dataset=train_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">test_dataloader = DataLoader(</span><br><span class="line">    dataset=test_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_datasets_size = <span class="built_in">len</span>(train_datasets)</span><br><span class="line">test_datasets_size = <span class="built_in">len</span>(test_datasets)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_datasets_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_datasets_size))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">runing_mode = <span class="string">&quot;gpu&quot;</span> <span class="comment"># cpu,gpu, gpus</span></span><br><span class="line"><span class="keyword">if</span> runing_mode == <span class="string">&quot;gpu&quot;</span> <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cuda&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cpu&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = LeNet()</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss_fn.to(device)</span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">epoch = <span class="number">10</span></span><br><span class="line">train_step, test_step = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;~~~~~~~~~~~~第&#123;&#125;轮训练开始~~~~~~~~~~~&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    start = time.time()</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">        output = model(imgs)</span><br><span class="line">        loss = loss_fn(output, targets)</span><br><span class="line"></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line"></span><br><span class="line">        train_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> train_step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;次训练，loss=&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(train_step, loss.item()))</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        test_loss, true_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">            output = model(imgs)</span><br><span class="line">            test_loss += loss_fn(output, targets)</span><br><span class="line">            true_num += (output.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;轮测试集上的loss:&#123;:.3f&#125;, 正确率为:&#123;:.3f&#125;%,耗时:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(test_step+<span class="number">1</span>, test_loss.item(), <span class="number">100</span> * true_num / test_datasets_size, end-start))</span><br><span class="line">    test_step += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>运行结果：<br>1.CPU<br><img src="https://img-blog.csdnimg.cn/14edcf10c0d446a189f4a6fc44fba1ce.png"><br>2.GPU<br><img src="https://img-blog.csdnimg.cn/f396f9c673a24d719516dd5abc055ba1.png"></p>
<h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5.Reference"></a>5.Reference</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u010881576/article/details/120919330">《Colab使用训练指南》 坚强的羊脂球</a></p>

    </div>
</article>

<div class="blog-post-comments">
  <section id="comment">
    <div id="valine_container" class="valine_thread"></div>
  </section>
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  <script>
    var GUEST_INFO = ["nick", "mail", "link"];
    var guest_info = "nick,mail,link"
      .split(",")
      .filter(function (item) {
        return GUEST_INFO.indexOf(item) > -1;
      });
    var valine = new Valine();
    valine.init({
      el: "#valine_container",
      appId: "",
      appKey: "",
      placeholder: "Just go go",
      pageSize: "15",
      avatar: "mp",
      lang: "zh-cn",
      emojiCDN: "https://mirrorcdn.bili33.top/",
      // 表情title和图片映射
      emojiMaps: {
        Tieba2: "Tieba/i_f01.png",
        Tieba3: "Tieba/i_f02.png",
        Tieba4: "Tieba/i_f03.png",
        Tieba5: "Tieba/i_f04.png",
        Tieba6: "Tieba/i_f05.png",
        Tieba7: "Tieba/i_f06.png",
        Tieba8: "Tieba/i_f07.png",
        Tieba9: "Tieba/i_f08.png",
        Tieba10: "Tieba/i_f09.png",
        Tieba11: "Tieba/i_f10.png",
        Tieba12: "Tieba/i_f11.png",
        Tieba13: "Tieba/i_f12.png",
        Tieba14: "Tieba/i_f13.png",
        Tieba15: "Tieba/i_f14.png",
        Tieba16: "Tieba/i_f15.png",
        Tieba17: "Tieba/i_f16.png",
        Tieba18: "Tieba/i_f17.png",
        Tieba19: "Tieba/i_f18.png",
        Tieba20: "Tieba/i_f19.png",
        Tieba21: "Tieba/i_f20.png",
        Tieba22: "Tieba/i_f21.png",
        Tieba23: "Tieba/i_f22.png",
        Tieba24: "Tieba/i_f23.png",
        Tieba25: "Tieba/i_f24.png",
        Tieba26: "Tieba/i_f25.png",
        Tieba27: "Tieba/i_f26.png",
        Tieba28: "Tieba/i_f27.png",
        Tieba29: "Tieba/i_f28.png",
        Tieba30: "Tieba/i_f29.png",
        Tieba31: "Tieba/i_f30.png",
        Tieba32: "Tieba/i_f31.png",
        Tieba33: "Tieba/i_f32.png",
        Tieba34: "Tieba/i_f33.png",
        bilibilitv2: "bilibilitv/[tv_doge].png",
        bilibilitv3: "bilibilitv/[tv_亲亲].png",
        bilibilitv4: "bilibilitv/[tv_偷笑].png",
        bilibilitv5: "bilibilitv/[tv_再见].png",
        bilibilitv6: "bilibilitv/[tv_冷漠].png",
        bilibilitv7: "bilibilitv/[tv_发怒].png",
        bilibilitv8: "bilibilitv/[tv_发财].png",
        bilibilitv9: "bilibilitv/[tv_可爱].png",
        bilibilitv10: "bilibilitv/[tv_吐血].png",
        bilibilitv11: "bilibilitv/[tv_呆].png",
        bilibilitv12: "bilibilitv/[tv_呕吐].png",
        bilibilitv13: "bilibilitv/[tv_困].png",
        bilibilitv14: "bilibilitv/[tv_坏笑].png",
        bilibilitv15: "bilibilitv/[tv_大佬].png",
        bilibilitv16: "bilibilitv/[tv_大哭].png",
        bilibilitv17: "bilibilitv/[tv_委屈].png",
        bilibilitv18: "bilibilitv/[tv_害羞].png",
        bilibilitv19: "bilibilitv/[tv_尴尬].png",
        bilibilitv20: "bilibilitv/[tv_微笑].png",
        bilibilitv21: "bilibilitv/[tv_思考].png",
        bilibilitv22: "bilibilitv/[tv_惊吓].png",
        bilibilitv23: "bilibilitv/[tv_打脸].png",
        bilibilitv24: "bilibilitv/[tv_抓狂].png",
        bilibilitv25: "bilibilitv/[tv_抠鼻].png",
        bilibilitv26: "bilibilitv/[tv_斜眼笑].png",
        bilibilitv27: "bilibilitv/[tv_无奈].png",
        bilibilitv28: "bilibilitv/[tv_晕].png",
        bilibilitv29: "bilibilitv/[tv_流汗].png",
        bilibilitv30: "bilibilitv/[tv_流泪].png",
        bilibilitv31: "bilibilitv/[tv_流鼻血].png",
        bilibilitv32: "bilibilitv/[tv_点赞].png",
        bilibilitv33: "bilibilitv/[tv_生气].png",
        bilibilitv34: "bilibilitv/[tv_生病].png",
        bilibilitv35: "bilibilitv/[tv_疑问].png",
        bilibilitv36: "bilibilitv/[tv_白眼].png",
        bilibilitv37: "bilibilitv/[tv_皱眉].png",
        bilibilitv38: "bilibilitv/[tv_目瞪口呆].png",
        bilibilitv39: "bilibilitv/[tv_睡着].png",
        bilibilitv40: "bilibilitv/[tv_笑哭].png",
        bilibilitv41: "bilibilitv/[tv_腼腆].png",
        bilibilitv42: "bilibilitv/[tv_色].png",
        bilibilitv43: "bilibilitv/[tv_调侃].png",
        bilibilitv44: "bilibilitv/[tv_调皮].png",
        bilibilitv45: "bilibilitv/[tv_鄙视].png",
        bilibilitv46: "bilibilitv/[tv_闭嘴].png",
        bilibilitv47: "bilibilitv/[tv_难过].png",
        bilibilitv48: "bilibilitv/[tv_馋].png",
        bilibilitv49: "bilibilitv/[tv_鬼脸].png",
        bilibilitv50: "bilibilitv/[tv_黑人问号].png",
        bilibilitv51: "bilibilitv/[tv_鼓掌].png",
        bilibili22332: "bilibili2233/[2233娘_卖萌].png",
        bilibili22333: "bilibili2233/[2233娘_吃惊].png",
        bilibili22334: "bilibili2233/[2233娘_吐魂].png",
        bilibili22335: "bilibili2233/[2233娘_喝水].png",
        bilibili22336: "bilibili2233/[2233娘_困惑].png",
        bilibili22337: "bilibili2233/[2233娘_大哭].png",
        bilibili22338: "bilibili2233/[2233娘_大笑].png",
        bilibili22339: "bilibili2233/[2233娘_委屈].png",
        bilibili223310: "bilibili2233/[2233娘_怒].png",
        bilibili223311: "bilibili2233/[2233娘_无言].png",
        bilibili223312: "bilibili2233/[2233娘_汗].png",
        bilibili223313: "bilibili2233/[2233娘_疑问].png",
        bilibili223314: "bilibili2233/[2233娘_第一].png",
        bilibili223315: "bilibili2233/[2233娘_耶].png",
        bilibili223316: "bilibili2233/[2233娘_郁闷].png",
      },
    });
  </script>
</div>



<script>
    //检测推送
    var pushType = "";
    var pushLink = "";
    var siteName = "AXDLMG7&#39;s Blog";
  
    var ValineButton = document.getElementsByClassName("vsubmit vbtn")[0];
    //分情况推送
    if (pushType === "sc") {
      var title = "text=" + siteName + "上又有新评论啦~!";
      function send_valine_Server() {
        //获取元素信息
        var pagename = document.title;
        var wz = pagename.indexOf("|");
        var res = pagename.substring(0, wz);
        var pageurl = document.URL;
        var ptime = new Date();
        var vnick = document.getElementsByClassName("vnick vinput")[0].value;
        var vmail = document.getElementsByClassName("vmail vinput")[0].value;
        var vlink = document.getElementsByClassName("vlink vinput")[0].value;
        var veditor = document.getElementsByClassName("veditor vinput")[0].value;
        var text = "desp=";
        var data =
          text +
          "|昵称：" +
          "|邮箱：" +
          "|网站地址：" +
          "|当前页面：" +
          "|评论内容：" +
          "|跳转链接：" +
          "|评论时间" +
          "\n" +
          "|----|----|----|----|" +
          "\n" +
          "|   " +
          vnick +
          "   |   " +
          vmail +
          "  |  " +
          vlink +
          "|   " +
          res +
          "| " +
          veditor +
          "| " +
          pageurl +
          "|" +
          ptime.toLocaleString() +
          "|";
        var httpRequest = new XMLHttpRequest(); //第一步：创建需要的对象
        httpRequest.open("POST", pushLink, true); //第二步：打开连接
        httpRequest.setRequestHeader(
          "Content-type",
          "application/x-www-form-urlencoded"
        ); //设置请求头 注：post方式必须设置请求头（在建立连接后设置请求头）
        httpRequest.send(title + "&" + data); //发送请求 将情头体写在send中
      }
      ValineButton.onclick = send_valine_Server;
    } else if (pushType === "qmsg") {
      var title = "msg=" + siteName + "上又有新评论啦~!\n";
      function send_valine_Qmsg() {
        //获取元素信息
        var pagename = document.title;
        var wz = pagename.indexOf("|");
        var res = pagename.substring(0, wz);
        var pageurl = document.URL;
        var ptime = new Date();
        var vnick = document.getElementsByClassName("vnick vinput")[0].value;
        var vmail = document.getElementsByClassName("vmail vinput")[0].value;
        var vlink = document.getElementsByClassName("vlink vinput")[0].value;
        var veditor = document.getElementsByClassName("veditor vinput")[0].value;
        var data =
          "昵称：" +
          vnick +
          "\n邮箱：" +
          vmail +
          "\n网站地址：" +
          vlink +
          "\n当前页面：" +
          pagename +
          "\n评论内容：" +
          veditor +
          "\n跳转链接：" +
          pageurl +
          "\n评论时间" +
          ptime.toLocaleString();
        var httpRequest = new XMLHttpRequest(); //第一步：创建需要的对象
        httpRequest.open("POST", pushLink, true); //第二步：打开连接
        httpRequest.setRequestHeader(
          "Content-type",
          "application/x-www-form-urlencoded"
        ); //设置请求头 注：post方式必须设置请求头（在建立连接后设置请求头）
        httpRequest.send(title + data); //发送请求 将情头体写在send中
      }
      ValineButton.onclick = send_valine_Qmsg;
    }
  </script>
    
        <div id="footer-post-container">
    <div id="footer-post">

        <div id="nav-footer" style="display: none">
            <ul>
                
                    <li><a href="/">首页</a></li>
                
                    <li><a href="/archives/">归档</a></li>
                
                    <li><a href="/categories/">分类</a></li>
                
                    <li><a href="/tags/">标签</a></li>
                
                    <li><a href="/about/">关于</a></li>
                
                    <li><a href="/search/">搜索</a></li>
                
            </ul>
        </div>

        <div id="toc-footer" style="display: none">
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">1.介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E6%9F%A5%E7%9C%8B%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">2.</span> <span class="toc-text">2.查看基本配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1%E6%9F%A5%E7%9C%8Bpytorch%E7%89%88%E6%9C%AC"><span class="toc-number">2.0.1.</span> <span class="toc-text">2.1查看pytorch版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8cuda"><span class="toc-number">2.0.2.</span> <span class="toc-text">2.2查看是否可以使用cuda</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E9%85%8D%E7%BD%AE"><span class="toc-number">2.0.3.</span> <span class="toc-text">2.3查看显卡配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E6%8C%82%E8%BD%BD"><span class="toc-number">3.</span> <span class="toc-text">3.挂载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E6%8C%82%E8%BD%BD%E8%B0%B7%E6%AD%8C%E4%BA%91%E7%9B%98"><span class="toc-number">3.0.1.</span> <span class="toc-text">31.挂载谷歌云盘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2%E6%9B%B4%E6%94%B9%E8%BF%90%E8%A1%8C%E7%9B%AE%E5%BD%95"><span class="toc-number">3.0.2.</span> <span class="toc-text">3.2更改运行目录</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E8%AE%AD%E7%BB%83"><span class="toc-number">4.</span> <span class="toc-text">4.训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Reference"><span class="toc-number">5.</span> <span class="toc-text">5.Reference</span></a></li></ol>
        </div>

        <div id="share-footer" style="display: none">
            <ul>
    <li><a class="icon"
           target="_blank" rel="noopener" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/&title=【Colab】基本操作【LeNet】【MNIST】训练测试"><i
                    class="fab fa-qq fa-lg" aria-hidden="true"></i></a></li>
    <li><a class="icon"
           target="_blank" rel="noopener" href="https://service.weibo.com/share/share.php?url=https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/&title=【Colab】基本操作【LeNet】【MNIST】训练测试"><i
                    class="fab fa-weibo fa-lg" aria-hidden="true"></i></a></li>
    <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/&text=【Colab】基本操作【LeNet】【MNIST】训练测试"><i
                    class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
    <li><a class="icon" href="mailto:?subject=【Colab】基本操作【LeNet】【MNIST】训练测试&body=Check out this article: https://guairen-7.github.io/2021/10/31/Colab+LeNet+MNIST/"><i
                    class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
</ul>
        </div>

        <div id="actions-footer">
            <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i
                        class="fas fa-bars fa-lg"
                        aria-hidden="true"></i> 菜单</a>
            <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i
                        class="fas fa-list fa-lg"
                        aria-hidden="true"></i> 目录</a>
            <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i
                        class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
            <a id="top" style="display:none" class="icon" href="#"
               onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg"
                                                                               aria-hidden="true"></i> 返回顶部
            </a>
        </div>

    </div>
</div>
    
    <footer id="footer">
  <div class="footer-top">
    &copy; 2022 <i class="fas fa-heart"></i>
    AXDLMG7 
  </div>

  <div class="footer-bottom">
    
    <!-- tongji -->
    <script
      async
      src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"
    ></script>
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
    <br />
     
  </div>
</footer>

</div>
<!-- styles -->

<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css">


<link rel="stylesheet" href="https://cdn.staticfile.org/justifiedGallery/3.7.0/css/justifiedGallery.min.css">

<!-- jquery -->

<script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script>


<script src="https://cdn.staticfile.org/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

    
<script src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script>

    <script type="text/javascript">
        $(function () {
            // copy-btn HTML
            var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板!\">";
            btn += '<i class="far fa-clone"></i>';
            btn += '</span>';
            // mount it!
            $(".highlight .code pre").before(btn);
            var clip = new ClipboardJS('.btn-copy', {
                target: function (trigger) {
                    return trigger.nextElementSibling;
                }
            });
            clip.on('success', function (e) {
                e.trigger.setAttribute('aria-label', "复制成功!");
                e.clearSelection();
            })
        })
    </script>


<script src="/js/main.js"></script>

<!-- search -->

</body>

</html>