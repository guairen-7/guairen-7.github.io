<!DOCTYPE html>
<html lang=zh-CN>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        【Colab】基本操作【LeNet】【MNIST】训练测试 - undefined
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_28hi1hpxx24.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>

    









<meta name="generator" content="Hexo 5.4.1"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i>  </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/" />
        </div>
        <div class="name">
            <i>AXDLMG7</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/collect/">
                    <i class="iconfont icon-shoucang1"></i>
                    <span>收藏</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">1.介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E6%9F%A5%E7%9C%8B%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-text">2.查看基本配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1%E6%9F%A5%E7%9C%8Bpytorch%E7%89%88%E6%9C%AC"><span class="toc-text">2.1查看pytorch版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8cuda"><span class="toc-text">2.2查看是否可以使用cuda</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E9%85%8D%E7%BD%AE"><span class="toc-text">2.3查看显卡配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E6%8C%82%E8%BD%BD"><span class="toc-text">3.挂载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1%E6%8C%82%E8%BD%BD%E8%B0%B7%E6%AD%8C%E4%BA%91%E7%9B%98"><span class="toc-text">3.1挂载谷歌云盘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2%E6%9B%B4%E6%94%B9%E8%BF%90%E8%A1%8C%E7%9B%AE%E5%BD%95"><span class="toc-text">3.2更改运行目录</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E8%AE%AD%E7%BB%83"><span class="toc-text">4.训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Reference"><span class="toc-text">5.Reference</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-bg" id="search-bg"></div>
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i>  </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        【Colab】基本操作【LeNet】【MNIST】训练测试
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2021-10-31 20:04:52</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#LeNet" title="LeNet">LeNet</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#MNIST" title="MNIST">MNIST</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p><a target="_blank" rel="noopener" href="https://colab.research.google.com/notebooks/welcome.ipynb">Colab 官网初始界面</a></p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h1><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/zh-cn/cuda-gpus">英伟达官网</a><br>谷歌将原来K80换成了T4<br><img src="https://img-blog.csdnimg.cn/7975074e2ece4cdc8be72e96851fd996.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p>
<h1 id="2-查看基本配置"><a href="#2-查看基本配置" class="headerlink" title="2.查看基本配置"></a>2.查看基本配置</h1><h3 id="2-1查看pytorch版本"><a href="#2-1查看pytorch版本" class="headerlink" title="2.1查看pytorch版本"></a>2.1查看pytorch版本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/b08a271c94da4d0293ac0dbc8ff3cc25.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_13,color_FFFFFF,t_70,g_se,x_16"></p>
<h3 id="2-2查看是否可以使用cuda"><a href="#2-2查看是否可以使用cuda" class="headerlink" title="2.2查看是否可以使用cuda"></a>2.2查看是否可以使用cuda</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/cce0d37208584800922981b38136b11f.png"><br>修改-&gt;笔记本设置-&gt;GPU<br><img src="https://img-blog.csdnimg.cn/38bcb5ea6f724e1a8a120bd71614efcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_19,color_FFFFFF,t_70,g_se,x_16"></p>
<h3 id="2-3查看显卡配置"><a href="#2-3查看显卡配置" class="headerlink" title="2.3查看显卡配置"></a>2.3查看显卡配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line">//注意英文感叹号</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/a222ea06ae0c44ce8f34592494dca1c3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p>
<h1 id="3-挂载"><a href="#3-挂载" class="headerlink" title="3.挂载"></a>3.挂载</h1><h3 id="3-1挂载谷歌云盘"><a href="#3-1挂载谷歌云盘" class="headerlink" title="3.1挂载谷歌云盘"></a>3.1挂载谷歌云盘</h3><p>Colab的运行原理实际上就是给你分配一台远程的带GPU的主机，所以它的原始路径不是你的谷歌云盘（也就是你的代码文件）所在的路径。所以第一步我们先要把谷歌云盘挂载带到那台远程主机上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&quot;/content/drive&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>登录谷歌账号并将验证码粘到框中</p>
<h3 id="3-2更改运行目录"><a href="#3-2更改运行目录" class="headerlink" title="3.2更改运行目录"></a>3.2更改运行目录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;/content/drive/MyDrive/Colab Notebooks/LeNet_MNIST_train_test&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>下面是我的目录结构<br><img src="https://img-blog.csdnimg.cn/a96be368c2ef4298af8e0fae94d4f61d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p>
<h1 id="4-训练"><a href="#4-训练" class="headerlink" title="4.训练"></a>4.训练</h1><p>【LeNet】+【MNIST】</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>),</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        output = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">train_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    dataset=train_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">test_dataloader = DataLoader(</span><br><span class="line">    dataset=test_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_datasets_size = <span class="built_in">len</span>(train_datasets)</span><br><span class="line">test_datasets_size = <span class="built_in">len</span>(test_datasets)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_datasets_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_datasets_size))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">runing_mode = <span class="string">&quot;gpu&quot;</span> <span class="comment"># cpu,gpu, gpus</span></span><br><span class="line"><span class="keyword">if</span> runing_mode == <span class="string">&quot;gpu&quot;</span> <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cuda&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cpu&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = LeNet()</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss_fn.to(device)</span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">epoch = <span class="number">10</span></span><br><span class="line">train_step, test_step = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;~~~~~~~~~~~~第&#123;&#125;轮训练开始~~~~~~~~~~~&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    start = time.time()</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">        output = model(imgs)</span><br><span class="line">        loss = loss_fn(output, targets)</span><br><span class="line"></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line"></span><br><span class="line">        train_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> train_step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;次训练，loss=&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(train_step, loss.item()))</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        test_loss, true_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">            output = model(imgs)</span><br><span class="line">            test_loss += loss_fn(output, targets)</span><br><span class="line">            true_num += (output.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;轮测试集上的loss:&#123;:.3f&#125;, 正确率为:&#123;:.3f&#125;%,耗时:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(test_step+<span class="number">1</span>, test_loss.item(), <span class="number">100</span> * true_num / test_datasets_size, end-start))</span><br><span class="line">    test_step += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>运行结果：<br>1.CPU<br><img src="https://img-blog.csdnimg.cn/14edcf10c0d446a189f4a6fc44fba1ce.png"><br>2.GPU<br><img src="https://img-blog.csdnimg.cn/f396f9c673a24d719516dd5abc055ba1.png"></p>
<h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5.Reference"></a>5.Reference</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u010881576/article/details/120919330">《Colab使用训练指南》 坚强的羊脂球</a></p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
        <div id="lv-container"></div>
        <div class="giscus"></div>
    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>  Theme <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.xml"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






</html>
