<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Kaggle GM Ruchi</title>
      <link href="/2022/01/26/Kaggle%20GM%20Ruchi/"/>
      <url>/2022/01/26/Kaggle%20GM%20Ruchi/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><font size=4><p>Ruchi目前是9个Kaggle Datasets Grandmasters之一，她的12个数据集中以9枚金牌和3枚银牌排名第5。她还是Notebooks and Discussion Master.</p><p>Ruchi于2020年毕业于<a href="https://simsr.somaiya.edu/en">KJ Somaiya工程学院</a>，获得计算机工程技术学士学位她目前在<a href="https://corp.colgate.com.cn/">高露洁棕榄公司</a>担任执行助理。她还是<a href="https://www.hp.com/cn-zh/home.html">HP</a>和<a href="https://www.nvidia.cn/">NVIDIA</a>的数据科学全球大使。</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><mark>您最近完成了计算机工程专业的毕业。是什么激发了您对数据科学和机器学习领域的兴趣？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>在我的本科课程中，在教授的众多课程中，由于我对从手头的数据中获得洞察力的兴趣，我被数据仓库和挖掘以及人工智能等学科所吸引。<strong>可以用机器学习的力量解决的现实问题将我吸引到这个领域。</strong></p><p>社交媒体仍然时不时地成为错误信息的中心，减轻这种情况是一个小时的需要。我最后一年的论文项目的重点是打击假新闻并根据其真实性对其进行分类。</p><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p><mark>哪些资源/书籍帮助您学习机器学习 ML？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>数学是我的强项，我精通统计学和线性代数。</p><p><strong>了解分布、随机性、矩阵乘法或概率等概念背后的数学原理很重要，以探索和理解数据并做出有意义的预测。</strong>有时微积分有助于在训练模型时了解损失和度量动态。</p><p>开始我的数据科学之旅时，我有7年的Java编程经验和1年的Python编程经验。我在与该领域相关的本科课程中选择的科目是用于数据科学、机器学习和人工智能的Python。</p><p>我还完成了 <a href="https://www.coursera.org/">Coursera</a> 上提供的 Andrew Ng 的课程：<a href="https://www.coursera.org/learn/machine-learning">机器学习</a>和深度学习专业化。我强烈建议初学者开始使用这些。</p><h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><p><mark>作为一名学生，您是如何平衡学业和这么多实习的？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>我的心态是探索所有领域，因为我对计算机科学充满热情，并选择对我挑战最大的领域。<strong>我想了解一下每个领域在现实世界中的运作方式，以及使用新技术解决现有问题的可能性。</strong></p><p><strong>我首先参加课程并确保我自己进行广泛的研究和项目。</strong>这样做之后，与那些在实习中学习的人相比，我在实习期间的大部分时间都花在与该领域直接相关的项目上。</p><p><strong>我认为花时间利用我们从理论中获得的知识并确保我们从中产生价值是至关重要的。当我们学习新事物并被它吸引时，这是利用这段时间尽我们所能做的最佳时机。</strong></p><h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><p><mark>您还是HP和NVIDIA的数据科学全球大使。请告诉我们这次经历以及它如何帮助您的数据科学工作流程？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>HP 和 NVIDIA 在 2020年选出了16位数据科学全球大使，我非常荣幸能成为其中的一员。我们获得了最先进的技术，可以在本地无缝地运行我们的数据科学工作流程。</p><p>拥有GPU使我们可以灵活地运行实验，而不受时间限制或同时运行的实验数量的限制。</p><h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><p><mark>您开始使用 Kaggle 的动机是什么？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>我对 Kaggle的第一个贡献是我从头开始策划的一个数据集。</p><p>补充：<br><a href="https://www.kaggle.com/ruchi798/movies-on-netflix-prime-video-hulu-and-disney">Dataset:Movies on Netflix, Prime Video, Hulu and Disney+</a></p><p><a href="https://www.kaggle.com/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney">Dataset:TV shows on Netflix, Prime Video, Hulu and Disney+</a></p><p>由于Netflix和Amazon Prime等流媒体应用程序在锁定期间被广泛使用，因此我想对这些流媒体应用程序在不同年龄段的流行程度进行分析。</p><p>但是我没有遇到相关的数据集。那时我决定自己制作并将其上传到 Kaggle上，因为它引起了轰动。这是一个全新的世界，人们可以与志同道合的人分享他们的工作和意识形态。</p><p>竞赛对我很有吸引力，但我想在全力以赴之前加强我的技能，因此我决定在这样做的同时继续为数据集和笔记本级别做出贡献。</p><h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><p><mark>您是Kaggle数据集大师，目前排名第5。您也是笔记本和讨论大师。你在这段旅程中遇到了哪些挑战，你是如何克服它们的？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>加入Kaggle后，最初的资源数量和信息量是压倒性的。为了让它深入人心，<strong>我开始过滤并专注于我正在处理的内容和问题陈述。</strong></p><p>对于一个新人来说，如果他们也感到有点气馁是可以理解的，<strong>但一个人必须坚持和开放的态度来内化新的想法和方法。</strong>我们可能只能定制一组特定的可能实验，但看看其他人如何处理相同的实验，这有助于我们更好地思考。<br>Kaggle上的迷你课程也帮助我获得了各种主题的方向感。这些是简短的课程，主要侧重于实用的关键学习。</p><h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><p><mark>您在12个数据集中获得了 9 枚金牌，您能否概述一下您从头开始创建数据集的整个过程？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>我相信通过用新颖的想法策划数据集，可以密切关注热门话题并为每个人创造价值。</p><p>一旦我选择了一个要解决的问题，我就会概述用例和所需的数据类型。如果我从多个来源聚合数据，我会记下必须转换以保持一致性的列。应注意不同来源数据的格式并进行相应修改。</p><p>我通过处理丢失的数据和应该消除的值来执行数据清理操作。在此之后，我开始生成与用例相关的新功能。</p><p>在Kaggle上传数据集时，我确保满足为便于其他人访问而指定的可用性要求：</p><ul><li><strong>数据集的简要描述</strong></li><li><strong>促使我创作它的灵感和动力</strong></li><li><strong>具体的描述</strong></li><li><strong>出处（来源和收集方法）</strong></li><li><strong>数据集的更新频率</strong></li></ul><h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><p><mark>一个好的数据集的特点是什么，在您看来一个好的数据集需要多少数据？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>就我自己而言，一个好的数据集是一个由属性表示的数据是完整的。丢失的数据应该是最小的，所以数据质量至关重要。</p><p>我们正在处理的数据对于类别应该是均衡的，并且对于任何特定类别都不会被低估。</p><p>数据是否足够完全取决于问题陈述及其用例，如果我们在训练工作流程中使用预训练模型，那么数据较少可能不是最坏的情况。拥有更多数据总是更好，但有些时候我们必须从头开始整理数据集。</p><h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><p><mark>在选择数据集后，您创建一个好的笔记本的过程究竟是什么？是否有一份您总是执行的必须完成的任务的清单？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>综合探索性数据分析与相关可视化相结合，帮助我们发现数据趋势和背景，这对改进我们的方法论很有成效。</p><p>一旦我选择了一个数据集，我唯一的目标就是通过<strong>EDA</strong> (Exploratory data analysis)的力量尽可能多地了解数据。当我们处理大型数据集时，可视化有助于我们发现异常和隐藏的趋势，否则可能会被忽视。</p><p>我们应该努力理解这些，并对异常值和特殊情况形成假设。通常，如果没有视觉表示，就很难理解数据。</p><p>在发布笔记本之前，我确实有一个任务清单。</p><ul><li>深入理解问题陈述是我的首要任务。 </li><li>每次创建笔记本时，我都会尝试实现更新的库。</li><li>解释一个特征，分析它的分布，研究特征的相互作用。</li><li>特征生成、展望未来。我在进行基线建模之前执行数据清理和特征编码。</li><li>为了获得更好的结果，我致力于随着时间的推移改进建模方法、调整参数并尝试新的实验。</li></ul><h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><p><mark>您如何让自己了解机器学习领域的所有快速进步？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>最初我想开始<strong>定期阅读论文和博客</strong>，现在它已成为我日常生活的一部分。我平均每天浏览5个博客。我的月度目标包括参考和彻底理解在至少2篇arxiv 研究论文/文章中采用和实施的新方法。</p><p>我还<strong>维护一个个人文档</strong>，其中包含我特别喜欢阅读的文章，将来可能想再次参考（按类别排序），我鼓励其他人尝试这种方法。</p><h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><p><mark>对于大学/学校学习的本科生，您有什么建议？</mark></p><p><strong>Ruchi Bhatia</strong>：<br>我相信Kaggle平台适合所有年龄段的人，每个人都有自己的东西。新手获得高质量的专家建议，专家获得更多他们感兴趣的材料以提高他们的洞察力。</p><p><strong>我们应该磨练我们的竞争力，但同时要专注于取得出色的成绩，最终目标应该始终是学习和应用我们获得的知识。</strong></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>微信公众号：Coggle数据科学</p></font>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Kaggle GM Philip</title>
      <link href="/2022/01/26/Kaggle%20GM%20Philip/"/>
      <url>/2022/01/26/Kaggle%20GM%20Philip/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><font size=4><p>“我只是按照自己的兴趣，尽可能多地专注于学习机器学习。年龄只是一个数字，何时开始以及可以实现多少没有上限。”<br>Philip是Kaggle Competitions Grandmaster，他以17枚金牌名列第 47 位。</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><mark>您在1979年读了新闻学本科，大约30年后在2012年选修了数据科学课程。什么促使您学习新技术并进入一个新领域？哪些资源/工具帮助您克服了这一差距？</mark></p><p><strong>Philip</strong>：<br>虽然我在大学主修新闻学，但我一直对计算机着迷，并在十几岁时开始编程。我作为技术作家的早期职业是我的写作和技术兴趣的良好结合。在做了大约15年的技术作者之后，我在接下来的20年里成为了一名连续创业者。</p><p>我参与的几乎所有初创公司都是数据驱动的公司，所以即使我的角色是管理和战略层面，我也保持与编程和数据的联系。我不记得我是如何登陆 Kaggle 网站的，但是当我意识到ML的能力时，我感觉好像我在旷野长途跋涉后终于回到了家。</p><p>我认为ML最吸引我的是它可以用来回答如此广泛的现实生活问题。我一直对解决实际问题比对理论研究更感兴趣。</p><p><strong>由于我多年没有做过任何编程，而且我的统计知识很初级，所以一开始我的学习曲线非常陡峭。我参加了很多在线课程，并关注Kaggle论坛来获取技巧。Kaggle排行榜在激励我继续学习方面非常有用。</strong></p><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p><mark>作为一个长期的技术作家，您在过渡到机器学习过程中遇到过什么困难吗？</mark></p><p><strong>Philip</strong>：<br>从技术作家和企业家转变为机器学习从业者绝对是一个挑战。我很幸运在经济上有保障，所以我没有任何压力要以数据科学家的身份谋生。我只是按照自己的兴趣，尽可能多地专注于学习。</p><h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><p><mark>您在机器学习领域的自由职业者方面也有丰富的经验。初学者在该领域自由职业时应避免哪些陷阱？</mark></p><p><strong>Philip</strong>：<br>我最喜欢自由职业者的一点是，每个数据集和数据问题都是独一无二的，需要定制的解决方案。<strong>我认为初学者的最大陷阱是假设每个新项目都与他们已经遇到的相似。我的经验是，这是个例外，该项目更有可能需要一个人来学习新技术。</strong></p><h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><p><mark>您是如何想到创立 Cozio Publishing 的？您之前是否有过编码经验？</mark></p><p><strong>Philip</strong>：<br>Cozio Publishing是在我的妻子想要购买一把“新”小提琴时成立的。有很多关于古董弦乐器的信息，但它们分散在不同的印刷出版物中——书籍、杂志、拍卖目录等。</p><p>当我帮助我的妻子收集信息时，我开始将数据输入自定义数据库，以便我们可以跟踪她正在考虑的不同仪器。在某个时候，我意识到其他音乐家可能会发现这些信息有用。</p><h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><p><mark>数据新闻——这是当今流行的流行词。你在这个领域有什么经验吗？它如何利用机器学习领域？</mark></p><p><strong>Philip</strong>：<br>虽然我是学新闻学的，是个技术作家，但实际上我已经很多年没有写过任何文章了，所以我不能真正评论数据新闻学，但这听起来很有趣。</p><h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><p><mark>你是Kaggle比赛的大师，目前排名第47。您参加了80多项比赛。这真太了不起了！如果我们具体谈谈您的 Kaggle 之旅，那么您面临哪些挑战，您是如何克服这些挑战的？</mark></p><p><strong>Philip</strong>：<br>我基本上是从零开始的，对机器学习、概率、统计或矩阵代数一无所知。我所拥有的只是一点数据库设计知识和一些非常生疏的 C 编程技能。</p><p>所以我必须一次学习所有东西R、Python、概率和统计，以及机器学习。<strong>我很幸运，正是在<a href="https://www.mooc.org/">MOOC</a>开始流行的时候开始了这段旅程。我的第一个在线课程之一，是著名的<a href="https://online.stanford.edu/courses/cs229-machine-learning">Andrew Ng ML</a>课程，另一个很棒的课程是Tibshirani和Hastie的<a href="https://www.edx.org/course/statistical-learning?index=undefined">斯坦福统计学习课程</a>。</strong></p><p><strong>我通过 <a href="https://www.coursera.org/">Coursera</a>、<a href="https://mitxonline.mit.edu/">MIT</a>、<a href="https://online.stanford.edu/">Stanford</a> 等在线学习了许多其他课程。</strong>这些课程的整体质量非常高。<br>补充：<br><a href="https://www.coursera.org/learn/machine-learning">Machine Learning|Andrew Ng|Coursera</a><br><a href="https://online.stanford.edu/courses/cs229-machine-learning">Machine Learning|Andrew Ng|Stanford Online</a></p><h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><p><mark>为了让初学者进入 Kaggle 比赛的前 1% 级别，您会给他们的五个提示是什么？</mark></p><p><strong>Philip</strong>：<br>我想我的第一个建议是设定一个不同的目标。如果高Kaggle排名是您的主要目标，您可能会想寻找捷径，例如混合大量公共内核。这可能对特定的比赛有帮助，但从长远来看无济于事。</p><p>所以我建议设定学习尽可能多的实用ML技术的目标。将每次Kaggle比赛用作学习机会，即使它不会在该比赛中获得高排名。如果我必须指定5个提示，我想它们是：</p><ul><li><strong>在查看论坛讨论和代码分享之前，可以尝试自己解决问题；</strong></li><li><strong>尽早开始，比赛中后期很难赶上比赛；</strong></li><li><strong>尝试与拥有更多知识/经验的人合作；</strong></li><li><strong>关注论坛，包含重要的信息；</strong></li><li><strong>如果排名下降，请耐心等待，不要沮丧。你学到的一切都会在未来的比赛中有所帮助；</strong></li></ul><h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><p><mark>迄今为止最具挑战性的两场比赛是哪一场，你是如何提出解决方案的？</mark></p><p><strong>Philip</strong>：<br>因为每场比赛都有独特的挑战。例如，在最近的内核竞赛中，最大的挑战通常是在内存和 CPU/GPU 限制内拟合模型。我投入最多时间和精力的比赛是 100 万美元的 <a href="https://www.kaggle.com/c/zillow-prize-1/overview">Zillow</a> 挑战赛。这里的主要挑战是一个非常庞大而丰富的数据集和非常积极的竞争对手。</p><p>我的最终解决方案获得了第二名，是多个LGB模型的融合结果。<strong>我的大部分努力都致力于特色工程和避免过度拟合。</strong></p><h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><p><mark>我们想知道您在构建机器学习模型时遵循了哪些步骤？</mark></p><p><strong>Philip</strong>：<br>我真的没有系统的方法论，<strong>但我通常从一些非常基本的EDA(Exploratory data analysis)和一个简单的模型开始来设置基线。对于许多比赛，一开始我花了很多时间来确保我有一个与训练/测试集拆分兼容的验证设置。一旦我对验证设置有信心，我将开始尝试逐步改进模型。</strong></p><p><strong>当我模型停止改进，或者如果我的验证分数与排行榜分数不同步，我将对数据进行更深入的分析以找出发生了什么。我通常避免查看任何公共内核，直到卡住为止。</strong></p><h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><p><mark>你在讨论中也很活跃。您会向初学者推荐哪些讨论主题？</mark></p><p><strong>Philip</strong>：<br>如果我以良好的排名完成比赛，我通常会发布我的解决方案摘要，偶尔我会发布一些关于比赛早期阶段的一般说明。</p><p><strong>我强烈建议大家一定要所有解决方案。</strong>这些非常有价值，因为它们通常包含非常有创意的技术，可以在未来的项目中使用。</p><h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><p><mark>对于想要过渡到机器学习的人，您有什么建议？</mark></p><p><strong>Philip</strong>：<br>我通常会避免这种类型的建议，因为人们是如此不同，对我有用的不一定对其他人有用。<strong>我的人生哲学一直是追随自己的兴趣，乐于学习新事物。</strong></p><p>这在ML中是必不可少的，它发展如此之快。最能激励我学习新技能的是具体问题，无论是 Kaggle 挑战还是自由职业项目。我知道有些人可以为了学习而激励自己学习。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>微信公众号：Coggle数据科学</p></font>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Kaggle GM Kostiantyn</title>
      <link href="/2022/01/26/Kaggle%20GM%20Kostiantyn/"/>
      <url>/2022/01/26/Kaggle%20GM%20Kostiantyn/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><font size=4>Kostiantyn是Kaggle Notebooks大师。他在该类别中排名第 8，拥有 17枚金牌，他具有计算机科学硕士学位。<p>本文我们将与Kostiantyn沟通，他的教育、工作和Kaggle之旅。</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><mark>大众的观点是在数据科学领域必须拥有硕士学位。你的硕士学位对你的职业生涯和Kaggle之旅有什么帮助？</mark></p><p><strong>Kostiantyn</strong>：<br>根据我的经验，我不能说数据科学职业必须获得硕士学位。我认识很多拥有学士/硕士学位或博士学位的人。</p><p>我认为本科学位对未来的职业非常重要，我们通常有很好的机会来训练纪律、沟通技巧、按时完成工作、解决复杂问题的能力。</p><p>同时我认为教育与Kaggle并不是强相关的，无论头衔和奖牌数量如何，Kaggle都是一个平台，您可以随时找到新事物或参加新领域的比赛。</p><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p><mark>你能分别描述一下在Akvelon 和 Quantum担任数据科学工程师的角色吗？工作角色是否因公司而异？</mark></p><p><strong>Kostiantyn</strong>：<br>在两家公司，主要职责是为各种客户解决数据科学领域的问题。主要区别在于要解决的任务的方向。在Akvelon中，大多数任务都与表格数据的经典机器学习相关。</p><p>在Quantum我有机会从事不同方向的工作，例如经典机器学习、计算机视觉，甚至NLP项目。</p><h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><p><mark>你是Kaggle Notebooks的大师，目前排名第 8。在此过程中遇到了哪些挑战，尤其是在创建第一个Notebook时，是如何克服这些挑战的？</mark></p><p><strong>Kostiantyn</strong>：<br>大约5年前，我创建了我的第一个Notebook。我认为许多初学者的主要挑战是克服对失败和批评的恐惧。</p><p>当我在我的第一个Notebook上工作时，我想我会发布它并在代码下获得很多负面评论。其实是我担心的多余了。</p><p>我面临的问题是创建一个<strong>清晰可读的内核</strong>，不仅仅是一个模型训练过程。</p><h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><p><mark>选择数据集后，你创建一个Notebook的过程是什么？是否有一份必须完成的任务的清单？</mark></p><p><strong>Kostiantyn</strong>：<br>我有一些标准计划，以此为基础构建我的内核。此外我有一个模板，通常可以帮助我以最快的方式构建我的笔记本。</p><p>所以我不需要花很多时间为所有数据集重写相同的代码，比如数据读取、一些可视化和基本分析。</p><p>一般而言Notebook应该包含以下内容：</p><ul><li><strong>数据读取</strong></li><li><strong>数据分析</strong></li><li><strong>缺失值分析</strong></li><li><strong>数值可视化</strong></li><li><strong>探索性数据分析</strong></li><li><strong>基线模型</strong></li></ul><h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><p><mark>到目前为止你最喜欢哪一场比赛？在提出解决方案时遇到了哪些挑战，如何最终达成解决方案的？</mark></p><p><strong>Kostiantyn</strong>：<br>我真的很喜欢参加kaggle比赛，但是由于空闲时间的限制，我真的很少认真参加，从比赛开始到比赛结束。我不认为我有最喜欢的一个，我过去的每场比赛都给我带来了一些新知识，有时也给我带来了与其他数据科学家的新联系。</p><p>对我来说主要的挑战是，人们通常在竞争指标中为百分之一、千分之一而战。而且通常情况下，金牌和没有金牌的区别真的很小。</p><h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><p><mark>你如何让自己跟上机器学习和深度学习领域的所有快速进步？</mark></p><p><strong>Kostiantyn</strong>：<br>今天有很多学习的机会，这并不取决于你的专业水平。我可以举例说明我使用的几种方法。</p><ul><li><strong>阅读最新的论文</strong></li><li><strong>学习最新的Kaggle比赛和分享</strong></li><li><strong>在数据科学社区进行交流</strong></li></ul><h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><p><mark>你对数据科学领域的初学者如何在该领域进行升级有什么建议？</mark></p><p><strong>Kostiantyn</strong>：</p><ul><li><p>第一个也是最重要的：<strong>永远不要停止学习新东西</strong>。 数据科学是一个发展非常迅速的领域。幸运的是，我们今天有很多学习的机会。您可以完成在线课程、阅读论文、参加不同的比赛，并与您的同事和数据科学领域的其他专家进行简单的讨论。</p></li><li><p>第二个：<strong>不要忘记你的编程技能</strong>。 好的数据科学家也应该是一个好的程序员。</p></li><li><p>最后一个：<strong>不要把你所有的空闲时间都花在工作上</strong>。 找到一个好的爱好，和家人一起开心，放松一下。在工作中筋疲力尽比你想象的要容易得多。</p></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>微信公众号：Coggle数据科学</p></font>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>NEWMEN（新贵）GM610键盘说明书</title>
      <link href="/2022/01/19/keyboard/"/>
      <url>/2022/01/19/keyboard/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><img src="https://img-blog.csdnimg.cn/903aee01f4c44dc9916249dab58e1ee4.png" alt="NEWMEN（新贵）GM610"></p><font size=4><h1 id="官方参数"><a href="#官方参数" class="headerlink" title="官方参数"></a>官方参数</h1><p>产品名称：GM610<br>产品颜色：白红<br>产品类型：蓝牙&amp;有线双模机械键盘<br>背光模式：RGB混光<br>按键数量：61键<br>轴体寿命：≥5000万次<br>轴体类型：黑<br>线材长度：1.6米PVC Type-C接口<br>按键无冲：全键无冲<br>产品重量：601g（不含线材）<br>键帽材质：PBT键帽<br>电池容量：1600mAh<br>键盘尺寸：291.5×101.5×38.5mm<br>工作电流：≤150mA（发光状态）；≤18mA（蓝牙无发光状态）</p><p><a href="http://newmen.com.cn/desc.php?id=129">Newmen-GM610</a></p><h1 id="我的参数"><a href="#我的参数" class="headerlink" title="我的参数"></a>我的参数</h1><p>型号Model：NEWMEN（新贵）GM610<br>轴体：黑轴<br>USB供电：电压5V  电流&lt;150mA<br>锂电池供电：电压3.7伏  电流&lt;150mA<br>产品序列号：KB948-210403938</p><h1 id="生产信息"><a href="#生产信息" class="headerlink" title="生产信息"></a>生产信息</h1><p>东莞市新贵电子科技有限公司<br>广东省东莞市塘厦镇林村西发路5号<br>网址：<a href="http://www.newmen.com.cn/">www.newmen.com.cn</a><br>客服热线：400-8866-811<br>执行标准号：键盘：GB/T 14081-2010</p><h1 id="FN快捷键"><a href="#FN快捷键" class="headerlink" title="FN快捷键"></a>FN快捷键</h1><p><strong>有线/蓝牙切换</strong><br>长按Fn+Tab三秒<br>红色-有线模式<br>蓝色-蓝牙模式  Q键闪烁绿色指示灯</p><p>Q-设备1<br>W-设备2<br>E-设备3</p><h1 id="2021-12-24固件升级后"><a href="#2021-12-24固件升级后" class="headerlink" title="2021.12.24固件升级后"></a>2021.12.24固件升级后</h1><p><img src="https://img-blog.csdnimg.cn/813fcc7608494d3f971a738b7ad20e9a.png" alt="2021.12.24更新"><br>1、增加FN多媒体等组合键，如图（ASDZXCVB）<br>2、增加MAC系统切换，如图（FN+P）<br>3、TAB指示灯修改，原为红或蓝色常亮，现改为每次切换后闪烁5次后变回主灯效<br>4、FN指示灯修改，原为五种颜色指示电量，现改为只有低电时FN闪烁红色指示灯<br>5、FN+ENTER将“？/alt/菜单/右CTRL”键切换为固定的方向键，其它按键功能只能按FN+组合</p><p><a href="http://newmen.com.cn/download.php?cid=92###">新贵中国官方网站-下载中心</a></p><h1 id="规格参数"><a href="#规格参数" class="headerlink" title="规格参数"></a>规格参数</h1><p>有线及蓝牙工作电流≤150mA（发光状态）<br>蓝牙：无发光工作电流≤18mA<br>2min待机电流≤0.8mA<br>30min休眠电流≤0.5mA</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>无线设备名：NEWMEN 3.0/NEWMEN 5.0<br>有线设备名：Newmen Bluetooth Keyboard<br>VID：12C9<br>PID：6001<br>Fn键电量指示灯：从低到高：红-黄-绿-蓝-白</p></font>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达来信：建立AI职业生涯的小tips</title>
      <link href="/2022/01/15/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9D%A5%E4%BF%A1/"/>
      <url>/2022/01/15/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9D%A5%E4%BF%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><font size=4>亲爱的朋友们,<p>人工智能持续创造着无数令人兴奋的工作机会，我知道你们中的许多人都希望在这个领域发展自己的职业生涯。虽然参加技术主题的网络课程是重要的一步，但成为一名人工智能专业人士需要的不仅仅是技术技能。最近，我一直在思考如何做更多的事情来支持所有想要在人工智能领域发展事业的人。</p><p>对于处在职业生涯不同阶段的人，成功的关键有哪些?</p><ul><li><p><strong>技术技能</strong>。通过参加网络课程或阅读课本来学习一项新技能。在这些课程中，专家将重要概念以易于理解的形式呈现出来，这是最有效的方法之一。</p></li><li><p><strong>实践经验</strong>。在掌握一项技能后，我们有必要通过将该技能应用于重要的项目来实践它，并学习有关的行业技巧。在实验室中表现良好的机器学习模型在现实世界中可能会遇到麻烦。在实际应用中获得的项目经验仍然是克服这些问题的重要组成部分。</p></li><li><p><strong>项目选择</strong>。选择要做的项目是人工智能中最难掌握的技能之一。我们在同时期只能做这么多项目，所以确定可行和有价值的项目——取得成功的可能性较大——是一个重要的步骤，必须在职业生涯中反复实践。</p></li><li><p><strong>团队合作</strong>。在处理大型项目时，团队合作比单打独斗更能取得成功。与他人合作、提供及听取建议的能力至关重要。这包括人际交往和沟通技巧。(顺便说一句，我以前也是个社恐。) </p></li><li><p><strong>网络</strong>。我讨厌网络！作为一个内向的人，当我不得不去参加聚会，微笑着和尽可能多的人握手是一种近乎恐怖的体验。我宁愿呆在家里看书。尽管如此，我还是很幸运地在人工智能领域找到了许多真正的朋友——我乐意为之辩护的人，以及我所依赖的人。没有人是孤立无援的，在你需要帮助或建议的时候，拥有一个强大的职业关系网可以帮助你前进。</p></li><li><p><strong>找工作</strong>。在建立事业的所有步骤中，这一步往往是最受关注的。不幸的是，我在网上看到很多关于这方面的不好的建议。(例如，很多文章似乎都在教唆你对未来的雇主采取敌对的态度，我认为这是没有帮助的)。尽管找工作似乎是最终目标，但它只是漫长职业生涯中的一小步。</p></li><li><p><strong>个人纪律</strong>。很少有人会知道你是把周末用来学习还是疯狂地看电视(除非你公布在社交媒体上！)，但随着时间的推移，他们就会注意到差异。许多成功人士在饮食、锻炼、睡眠、人际关系、工作、学习和自我照顾方面都养成了良好的习惯。这样的习惯可以帮助他们在保持健康的同时继续进步。</p></li><li><p><strong>利他主义</strong>。我发现，那些在自己人生旅途的每一步都致力于帮助他人的人，往往会得到更好的结果。我们如何在为自己打造一份令人兴奋的事业同时帮助他人呢?</p></li></ul><p>上述的每一项都是一个复杂的主题，值得写一整本书。我会继续思考我们如何共同努力，支持每个人的职业目标。同时，我也想听听你的想法。我漏掉了什么？我或我的团队能做些什么来支持你们的事业?</p><p>Keep learning!</p><p>Andrew<br></font></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.bilibili.com/read/cv14819658?spm_id_from=444.41.0.0">吴恩达来信：建立AI职业生涯的小tips by:deeplearning_ai from:bilibili</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Andrew Ng&#39;s development advice for students in AI field</title>
      <link href="/2022/01/02/Andrew%20Ng&#39;s%20development%20advice%20for%20students%20in%20AI%20field/"/>
      <url>/2022/01/02/Andrew%20Ng&#39;s%20development%20advice%20for%20students%20in%20AI%20field/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="关于如何阅读文献"><a href="#关于如何阅读文献" class="headerlink" title="关于如何阅读文献"></a>关于如何阅读文献</h1><font size=4>深度学习领域的发展真的很快，以至于即使你已十分熟悉深度学习的基础内容，还是很难做到在理论和实践知识上都与行业与时俱进，因此，能否有效阅读文献对开发和研究者们来说可谓是尤其重要，我可以给你们一些参考建议。通常我们都会觉得“学会怎么读论文”是一个潜移默化的过程，但我希望这次分享内容能帮你们加速这一过程。<p>现在，假设你想通过阅读文献来增近对某一特定领域的了解，比如自然语言处理，我会采取的策略是<strong>先汇总一份需要阅读的论文清单</strong>，这些论文的来源可以是 arXiv，互联网，Medium 博文，或者 GitHub 上的一些帖子。</p><p>但不管你的学习资源来自哪里，<strong>在你汇总出一份文献清单后，我推荐“并行+扩充阅读法”，而非按清单从上往下，一篇篇从头读到尾。</strong></p><p><strong>（清单+百分比，速读）</strong><br>首先，画一个表格，表格的纵轴上列出你待读清单上的论文，横轴上是一篇论文的读完百分比（从百分之零到百分之百），然后对所有的论文进行速读，<strong>大概掌握每篇论文要讲什么</strong>，将每篇论文的阅读进度都完成到约百分之十。</p><p><strong>（判断meanless与具有key massage的Paper，花费不同的时间与精力）</strong><br>然后在此基础上，如果我们能判断出清单上有那种“意义不大”的论文，即使有许多论文都引用了它，也不要害怕说自己判断错了，要大胆相信自己的判断，将它移出清单，而除此之外，我们通常也能在这一过程中判断出，哪些论文是那些具有关键信息的文献，而一旦识别出了这些文献，我们便要花更多的时间和精力去细读它们。</p><p><strong>（按照一种“树形”结构去理解重点且基础文献，注意树枝不要太长）</strong><br>如此一来，我们便有可能在这一细读的过程中又发掘出一些新的文献，然后在发觉到“要理解当下细读文献的内容，需要先读新发掘出的文献”时，我们就要先去阅读那篇新发掘出的更为基础的文献，然后再在阅读这篇新发掘出的文献时重复刚才的过程，直到找到一篇能直接读到底的文献，将它读完后，再回去将之前引出这篇“底部文献”的那些文献按顺序一一读完。</p><p>而就论文的阅读数量来说，<strong>一般需要读 15 到 20 篇论文，才能对一个细枝领域有一些基本的了解</strong>，并也只有是在这一基础上，才能进行一些真正意义上的实践，在有理解的基础上实现一些算法。</p><p><strong>通常，在读了 50 到 100 篇论文后，能对想要了解的某一细枝领域有一个相对较好的了解</strong>。而如果只是读 5 到 20 篇文献，我们或许能实现一些算法，但没法跟上该领域的前沿进展。</p><p>个人来说，我在阅读一篇论文时，通常会将阅读的过程分为几步。</p><ul><li>第一步是读论文的<strong>标题、摘要和图表</strong>。</li></ul><p>图表们在深度学习领域的论文中尤为重要，很多论文都会用图表来概括整篇论文所讲的内容。取决于具体的需要，<strong>我或许还会略读一下论文的方法和实验部分</strong>，然后通过以上所有，我就能在不细读整篇论文的情况下，较好地了解论文是要讲什么。</p><ul><li>在第一步的基础上，我会开始第二步，<strong>细读论文的 Introduction（介绍）和结论，并细读这两个部分中所使用到的图表。</strong></li></ul><p>而对于论文中的 <strong>Related Work（相关研究）部分</strong>，很多人会在第一次阅读时略过，原因是如果在开始阅读前对论文所涉及的领域了解不深，可能根本读不懂这里讲的是什么，但如果我们决定要阅读这一部分，需要<strong>注意这一部分内容客观性</strong>，很多作者在书写这一部分时，都是选那些能支持论文内容的材料写进来，作为“说服审稿人发表这篇论文”之努力的一部分，所以这里要有这个意识，注意这个部分的客观性。</p><ul><li><p>在进行完第二步后，第三步的内容非常简单，就是<strong>先略过理论的数学部分</strong>来读论文，然后我们便可以进行下一步了。</p></li><li><p>第四步，<strong>通读全文</strong>，<strong>但要在阅读过程中略过讲不通的部分</strong>，原因是实际发表论文时，都会尝试将论文包装成一种前沿研究，而有时我们其实并不知道所写的论文里哪些重要，哪些可能其实不重要。</p></li></ul><p>因此，在很多被大量引用的论文中，大家在后来都是发现说这些论文的部分内容十分有用，而有的部分则是根本不重要，但重点是，作者在写论文的时候是没法知道这些的，通常没法在写论文时就知道所写的内容里哪些比较重要，哪些不重要。</p><p>比如 Yann LeCun 的 LeNet 系列论文，论文中有的内容成为了卷积神经网络发展的基石，有的内容则是一些不太相干的东西，比如 Transducers 等概念，这些在现在很少有人会用。</p><p>所以，当你在阅读一篇论文时觉得<strong>“有的东西讲不通，或者根本没什么用”时，不用怀疑自己，跳过就行了</strong>。当然，如果你想做关于某一方面的深度研究，那当我没说。</p><p>一般来说，我个人按以上方法读完一篇论文需要大概 30 分钟，但我在机器学习领域算是比较专业了，掌握的信息很多，所以能在大概半小时内读完，你们可以按照自己的速度来，不用参照我的时间。<br></font></p><h1 id="关于文献的来源"><a href="#关于文献的来源" class="headerlink" title="关于文献的来源"></a>关于文献的来源</h1><font size=4>另外一个我经常会被问到的，关于阅读文献的问题。<p>一般去哪里搜集需要阅读的文献？关于这一点，我想说的是，上网检索是非常重要的。关于一个话题的相关信息，无论是论文还是技术博文，你都能通过网上检索找到。</p><p>此外，很多人都想做到说，自己掌握的信息能否“实时”与深度学习这一领域的前沿发展接轨，关于这一点，我觉得<strong>T特</strong>现在已经成了科研人员们用于发现新事物的一个好地方，除此以外，在 <strong>Reddit</strong> 上关注机器学习话题也会有所帮助。当然，关注<strong>领域内的会议</strong>作用也很大，比如 NIPS、ICML 和 ICLR。<br></font></p><h1 id="关于深度阅读文献"><a href="#关于深度阅读文献" class="headerlink" title="关于深度阅读文献"></a>关于深度阅读文献</h1><font size=4><p>关于阅读文献我还想再补充两点：</p><ul><li>很多论文或其它资料里都有<strong>数学内容</strong>，有时这些数学内容里的推导可能非常难懂，而如果你想确保自己有读懂这些内容，我的建议是<strong>先通读一遍，然后看自己能不能从论文中给出的推导的起点，推出后面的那些算式，如果你能成功完成推导的话，那你绝对是已经完全读懂了这篇论文。</strong></li></ul><p>而就我个人来说，由于我在读博士时就经常这么做，我发现这种做法后来<strong>除了能帮我读懂别人的研究，还有锻炼发现新算法的能力。</strong></p><p>当然，这么做会需要你花费大量的时间，要不要这么做还是取决于你的具体需求，比如你是否真的想要完全读懂一篇论文。</p><ul><li>关于如何读懂<strong>代码</strong>，与数学部分类似，我的建议是，<strong>如果你想完全搞懂这篇论文所用的代码，就尝试在看完代码以后，重新实现一遍论文所用的代码，如果能成功实现的话，便说明你已经完全搞懂论文所用的代码了。</strong></font></li></ul><h1 id="关于文献阅读习惯的长期建议"><a href="#关于文献阅读习惯的长期建议" class="headerlink" title="关于文献阅读习惯的长期建议"></a>关于文献阅读习惯的长期建议</h1><font size=4><p><strong>在长期上，我建议常读论文，而不是采取那种突击式读论文的方法</strong>，比如可以每周读一两篇，而不是在感恩节假期时突击读它个 50 篇然后就再也不读了。<br>从教育学和脑科学上来说，这么做也能帮我们养成一个良好的习惯。<br></font></p><h1 id="关于职业发展"><a href="#关于职业发展" class="headerlink" title="关于职业发展"></a>关于职业发展</h1><font size=4>之前很多学生都有问我要一些关于职业发展的建议，这也确实是一个很重要的问题，比如就我们所知，现在机器学习所涉及的领域真的是太广了，如何才能知道自己究竟想做什么呢？<p>首先，我需要做一个假设，就是大多数人，都只想在职业发展上涉及一到两个领域。</p><p>无论你是想留在大学里，还是去公司里工作，我都希望你们所从事的工作是重要的，或者说，是有意义的，然后在此基础上，我想谈两个与职业发展有关的问题，一是要怎么拿到一个职位（Phd，教职或是公司职位），二是我们要如何着眼于长期规划来选择职位。</p><p><strong>1、关于找工作，招聘官们在寻找什么样的人？</strong></p><p>首先，很多招聘官们都会青睐那些<strong>有专业技能的人</strong>，比如在机器学习领域，很多面试官会问你，你会不会用这种方法或是那种方法，然后再细问一些关于特定方法的问题，比如，在使用 batch gradient descent 这一方法时，调整 mean batch size 会有什么样的影响等等。然后，除了你在机器学习上的知识，很多面试官也会关注你的编程能力。</p><p>此外，他们还会关注“你之前做过哪些有意义的工作”，原因是一个人有很棒的理论知识基础，并不能说明这个人就能很好的使用这些理论，所以，<strong>如果能有一些理论实践的话将是很好的。</strong></p><p>许多面试官也会看重面试者的<strong>持续学习能力。</strong></p><p>很多工作并不需要你是个“全通”，你只需在对机器学习有一个整体的了解上，能做到相对精通那份工作会涉及到的领域的内容就行了。</p><p>关于这个有很多衡量标准，有时面试官可能会想要了解你此前在有关领域内的工作，或者是你此前在有关领域内产出的一些开源代码，这些信息能帮助面试官判断<strong>“你是否能就一个问题给出有效的解决方案”。</strong></p><p><strong>2、如何选择一份工作</strong></p><p><strong>如果你的目标是想做到持续学习，和厉害的人从事有意义的工作是很重要的，环境的熏陶有时还是能带来蛮大影响的。</strong></p><p>所以，在选择自己想要去哪里工作时，要注意那里的团队怎么样，是否是自己想要的一个环境。</p><p>还有就是，<strong>你是否觉得那份工作的上级与你合得来。</strong></p><p>最后就是<strong>公司品牌</strong>。比起品牌，你更需要关注的是你是否能与可能的上司合得来，是否能与团队合得来，是否喜欢那里的工作环境，这一点对于很多招聘官来说也是一样的，<strong>招聘和面试官们比起你之前在哪工作过，会更关注你是个什么样的人。</strong></p><p>另外，如果一份工作在你收到 offer 后拒绝给你透露你将要进行的项目内容、团队和上级信息，要提高警惕。因为这种情况下，如果没有特殊原因，意味着将这些信息透露给你将会降低这份工作对你的吸引力。</p><p>最后，还是之前谈到的，可能是最重要的一个建议，在选择工作时，<strong>选择那些你觉得有意义的工作，并在工作中积极学习你能学到的东西。</strong></p><p>我个人觉得，未来，AI 并不是只有在这些科技公司里才能用的上，而是在很多被视作“传统行业”的领域里都能大显身手，所以在职业选择上，<strong>我建议不用把自己限制在科技行业里。</strong><br></font></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>First principles thinking</title>
      <link href="/2021/12/24/First%20principles%20thinking/"/>
      <url>/2021/12/24/First%20principles%20thinking/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p> <font face=黑体 size=4>第一性原理（First principle thinking，又称“第一原理”）</p><p>古希腊哲学家亚里士多德：在每一系统的探索中，存在第一原理，是一个最基本的命题或假设，不能被省略或删除，也不能被违反。 ”</p><p>下面片段节选自James Clear的《Atomic Habits》:</font></p><p> <font face=Georgia size=10>F</font><font face=Georgia size=5>irst principles thinking, which is sometimes called reasoning from first principles, is one of the most effective strategies you can employ for breaking down complicated problems and generating original solutions. It also might be the single best approach to learn how to think for yourself.</p><p>The first principles approach has been used by many great thinkers including inventor Johannes Gutenberg, military strategist John Boyd, and the ancient philosopher Aristotle, but no one embodies the philosophy of first principles thinking more effectively than entrepreneur Elon Musk.</p><p>In 2002, Musk began his quest to send the first rocket to Mars—an idea that would eventually become the aerospace company SpaceX.</p><p>He ran into a major challenge right off the bat. After visiting a number of aerospace manufacturers around the world, Musk discovered the cost of purchasing a rocket was astronomical—up to $65 million. Given the high price, he began to rethink the problem.</p><p>“I tend to approach things from a physics framework,” Musk said in an interview. “Physics teaches you to reason from first principles rather than by analogy. So I said, okay, let’s look at the first principles. What is a rocket made of? Aerospace-grade aluminum alloys, plus some titanium, copper, and carbon fiber. Then I asked, what is the value of those materials on the commodity market? It turned out that the materials cost of a rocket was around two percent of the typical price.”</p><p>Instead of buying a finished rocket for tens of millions, Musk decided to create his own company, purchase the raw materials for cheap, and build the rockets himself. SpaceX was born.</p><p>Within a few years, SpaceX had cut the price of launching a rocket by nearly 10x while still making a profit. Musk used first principles thinking to break the situation down to the fundamentals, bypass the high prices of the aerospace industry, and create a more effective solution.</p><p>First principles thinking is the act of boiling a process down to the fundamental parts that you know are true and building up from there. Let’s discuss how you can utilize first principles thinking in your life and work.</font></p><h1 id="Defining-First-Principles-Thinking"><a href="#Defining-First-Principles-Thinking" class="headerlink" title="Defining First Principles Thinking"></a>Defining First Principles Thinking</h1><p><font face=Georgia size=5>A first principle is a basic assumption that cannot be deduced any further. Over two thousand years ago, Aristotle defined a first principle as “the first basis from which a thing is known.”</p><p>First principles thinking is a fancy way of saying “think like a scientist.” Scientists don’t assume anything. They start with questions like, What are we absolutely sure is true? What has been proven?</p><p>In theory, first principles thinking requires you to dig deeper and deeper until you are left with only the foundational truths of a situation. Rene Descartes, the French philosopher and scientist, embraced this approach with a method now called Cartesian Doubt in which he would “systematically doubt everything he could possibly doubt until he was left with what he saw as purely indubitable truths.”</p><p>In practice, you don’t have to simplify every problem down to the atomic level to get the benefits of first principles thinking. You just need to go one or two levels deeper than most people. Different solutions present themselves at different layers of abstraction. John Boyd, the famous fighter pilot and military strategist, created the following thought experiment which showcases how to use first principles thinking in a practical way.</p><p>Imagine you have three things:</p><p>A motorboat with a skier behind it<br>A military tank<br>A bicycle<br>Now, let’s break these items down into their constituent parts:</p><p>Motorboat: motor, the hull of a boat, and a pair of skis.<br>Tank: metal treads, steel armor plates, and a gun.<br>Bicycle: handlebars, wheels, gears, and a seat.<br>What can you create from these individual parts? One option is to make a snowmobile by combining the handlebars and seat from the bike, the metal treads from the tank, and the motor and skis from the boat.</p><p>This is the process of first principles thinking in a nutshell. It is a cycle of breaking a situation down into the core pieces and then putting them all back together in a more effective way. Deconstruct then reconstruct.</font></p><h1 id="How-First-Principles-Drive-Innovation"><a href="#How-First-Principles-Drive-Innovation" class="headerlink" title="How First Principles Drive Innovation"></a>How First Principles Drive Innovation</h1><p><font face=Georgia size=5>The snowmobile example also highlights another hallmark of first principles thinking, which is the combination of ideas from seemingly unrelated fields. A tank and a bicycle appear to have nothing in common, but pieces of a tank and a bicycle can be combined to develop innovations like a snowmobile.</p><p>Many of the most groundbreaking ideas in history have been a result of boiling things down to the first principles and then substituting a more effective solution for one of the key parts.</p><p>For instance, Johannes Gutenberg combined the technology of a screw press—a device used for making wine—with movable type, paper, and ink to create the printing press. Movable type had been used for centuries, but Gutenberg was the first person to consider the constituent parts of the process and adapt technology from an entirely different field to make printing far more efficient. The result was a world-changing innovation and the widespread distribution of information for the first time in history.</p><p>The best solution is not where everyone is already looking.</p><p>First principles thinking helps you to cobble together information from different disciplines to create new ideas and innovations. You start by getting to the facts. Once you have a foundation of facts, you can make a plan to improve each little piece. This process naturally leads to exploring widely for better substitutes.</font></p><h1 id="The-Challenge-of-Reasoning-From-First-Principles"><a href="#The-Challenge-of-Reasoning-From-First-Principles" class="headerlink" title="The Challenge of Reasoning From First Principles"></a>The Challenge of Reasoning From First Principles</h1><p><font face=Georgia size=5>First principles thinking can be easy to describe, but quite difficult to practice. One of the primary obstacles to first principles thinking is our tendency to optimize form rather than function. The story of the suitcase provides a perfect example.</p><p>In ancient Rome, soldiers used leather messenger bags and satchels to carry food while riding across the countryside. At the same time, the Romans had many vehicles with wheels like chariots, carriages, and wagons. And yet, for thousands of years, nobody thought to combine the bag and the wheel. The first rolling suitcase wasn’t invented until 1970 when Bernard Sadow was hauling his luggage through an airport and saw a worker rolling a heavy machine on a wheeled skid.</p><p>Throughout the 1800s and 1900s, leather bags were specialized for particular uses—backpacks for school, rucksacks for hiking, suitcases for travel. Zippers were added to bags in 1938. Nylon backpacks were first sold in 1967. Despite these improvements, the form of the bag remained largely the same. Innovators spent all of their time making slight iterations on the same theme.</p><p>What looks like innovation is often an iteration of previous forms rather than an improvement of the core function. While everyone else was focused on how to build a better bag (form), Sadow considered how to store and move things more efficiently (function).</font></p><h1 id="How-to-Think-for-Yourself"><a href="#How-to-Think-for-Yourself" class="headerlink" title="How to Think for Yourself"></a>How to Think for Yourself</h1><p><font face=Georgia size=5>The human tendency for imitation is a common roadblock to first principles thinking. When most people envision the future, they project the current form forward rather than projecting the function forward and abandoning the form.</p><p>For instance, when criticizing technological progress some people ask, “Where are the flying cars?”</p><p>Here’s the thing: We have flying cars. They’re called airplanes. People who ask this question are so focused on form (a flying object that looks like a car) that they overlook the function (transportation by flight). This is what Elon Musk is referring to when he says that people often “live life by analogy.”</p><p>Be wary of the ideas you inherit. Old conventions and previous forms are often accepted without question and, once accepted, they set a boundary around creativity.</p><p>This difference is one of the key distinctions between continuous improvement and first principles thinking. Continuous improvement tends to occur within the boundary set by the original vision. By comparison, first principles thinking requires you to abandon your allegiance to previous forms and put the function front and center. What are you trying to accomplish? What is the functional outcome you are looking to achieve?</p><p>Optimize the function. Ignore the form. This is how you learn to think for yourself.</font></p><h1 id="The-Power-of-First-Principles"><a href="#The-Power-of-First-Principles" class="headerlink" title="The Power of First Principles"></a>The Power of First Principles</h1><p><font face=Georgia size=5>Ironically, perhaps the best way to develop cutting-edge ideas is to start by breaking things down to the fundamentals. Even if you aren’t trying to develop innovative ideas, understanding the first principles of your field is a smart use of your time. Without a firm grasp of the basics, there is little chance of mastering the details that make the difference at elite levels of competition.</p><p>Every innovation, including the most groundbreaking ones, requires a long period of iteration and improvement. The company at the beginning of this article, SpaceX, ran many simulations, made thousands of adjustments, and required multiple trials before they figured out how to build an affordable and reusable rocket.</p><p>First principles thinking does not remove the need for continuous improvement, but it does alter the direction of improvement. Without reasoning by first principles, you spend your time making small improvements to a bicycle rather than a snowmobile. First principles thinking sets you on a different trajectory.</p><p>If you want to enhance an existing process or belief, continuous improvement is a great option. If you want to learn how to think for yourself, reasoning from first principles is one of the best ways to do it.</font></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>11月3日-11月14日文章分享</title>
      <link href="/2021/11/15/11%E6%9C%883%E6%97%A5-11%E6%9C%8814%E6%97%A5%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/"/>
      <url>/2021/11/15/11%E6%9C%883%E6%97%A5-11%E6%9C%8814%E6%97%A5%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>@[TOC]</p><h1 id="1-教育"><a href="#1-教育" class="headerlink" title="1.教育"></a>1.教育</h1><h2 id="1-1-Albert-Einstein"><a href="#1-1-Albert-Einstein" class="headerlink" title="1.1 Albert Einstein"></a>1.1 Albert Einstein</h2><p><a href="https://new.qq.com/omn/20210202/20210202A031QZ00.html">爱因斯坦：教育的首要目标是什么？—腾讯新闻</a></p><h2 id="1-2-论学术与学术标准—李伯重"><a href="#1-2-论学术与学术标准—李伯重" class="headerlink" title="1.2 论学术与学术标准—李伯重"></a>1.2 论学术与学术标准—李伯重</h2><p><a href="https://www.cnki.net/KCMS/detail/detail.aspx?filename=SKLU200503001&dbname=cjfdtotal&dbcode=CJFD&v=MDk5NjFpYkhlN0c0SHRUTXJJOUZaWVI2RGc4L3poWVU3enNPVDNpUXJSY3pGckNVUjd1ZVp1ZHFGQ3JsVjc3QU4=">论学术与学术标准—李伯重</a></p><h2 id="1-3-康毅滨"><a href="#1-3-康毅滨" class="headerlink" title="1.3 康毅滨"></a>1.3 康毅滨</h2><p><a href="https://mp.weixin.qq.com/s/tYg3wwxJxPNrK7g4L3DRWg">《星期日新闻晨报》康毅滨访谈</a></p><h2 id="1-4-亲子教育"><a href="#1-4-亲子教育" class="headerlink" title="1.4 亲子教育"></a>1.4 亲子教育</h2><p><a href="https://mp.weixin.qq.com/s/EC2RzHZ_d4nR85Vs7x-6UA">100幅心理漫画告诉我们：教育可以很简单</a></p><h1 id="2-人物"><a href="#2-人物" class="headerlink" title="2.人物"></a>2.人物</h1><h2 id="2-1-清华大学本科生特等奖学金答辩"><a href="#2-1-清华大学本科生特等奖学金答辩" class="headerlink" title="2.1 清华大学本科生特等奖学金答辩"></a>2.1 清华大学本科生特等奖学金答辩</h2><p><a href="https://www.tsinghua.edu.cn/info/1181/88823.htm">2021年清华大学本科生特等奖学金答辩会举行</a></p><h2 id="2-2-John-von-Neumann"><a href="#2-2-John-von-Neumann" class="headerlink" title="2.2 John von Neumann"></a>2.2 John von Neumann</h2><p><a href="https://www.cantorsparadise.com/the-unparalleled-genius-of-john-von-neumann-791bb9f42a2d">The Unparalleled Genius of John von Neumann—Jørgen Veisdal</a></p><h2 id="2-3-华科团队EDA全球冠军"><a href="#2-3-华科团队EDA全球冠军" class="headerlink" title="2.3 华科团队EDA全球冠军"></a>2.3 华科团队EDA全球冠军</h2><p><a href="http://iccad-contest.org/2021/Problems.html">CAD Contest</a></p><p><a href="http://iccad-contest.org/2021/ProblemB-cada0136.mp4">华科团队EDA全球冠军解决方案mp4</a></p><h2 id="2-4-Jure-Leskovec"><a href="#2-4-Jure-Leskovec" class="headerlink" title="2.4 Jure Leskovec"></a>2.4 Jure Leskovec</h2><p>研究方向:<br>applied machine learning for large interconnected systems focusing on modeling complex, richly-labeled relational structures, graphs, and networks for systems at all scales, from interactions of proteins in a cell to interactions between humans in a society. Applications include commonsense reasoning, recommender systems, computational social science, and computational biology with an emphasis on drug discovery.</p><p><a href="https://cs.stanford.edu/people/jure/">Jure Leskovec  @  Stanford</a></p><p><a href="https://arxiv.org/abs/1810.00826#">Paper—How Powerful are Graph Neural Networks?</a></p><p><a href="https://static.aminer.cn/misc/pdf/graphsage2-mit-nov19.pdf">Jure Leskovec清华演讲PPT—AMiner</a></p><h2 id="2-5-Yann-LeCun"><a href="#2-5-Yann-LeCun" class="headerlink" title="2.5 Yann LeCun"></a>2.5 Yann LeCun</h2><p><a href="https://www.yicai.com/news/5272525.html">法国极客Yann LeCun：掌舵Facebook人工智能 | 完美人物志</a></p><p><a href="https://www.leiphone.com/category/ai/62TcDCKFomfCEWnQ.html">Yann LeCun专访：我不觉得自己有天分，但是我一直往聪明人堆里钻</a></p><h2 id="2-6-何恺明"><a href="#2-6-何恺明" class="headerlink" title="2.6 何恺明"></a>2.6 何恺明</h2><p><a href="http://kaiminghe.com/">Kaiming He</a></p><p><a href="https://arxiv.org/abs/2111.06377">Masked Autoencoders Are Scalable Vision Learners</a></p><p><a href="https://ai.facebook.com/">FAIR</a></p><h2 id="2-7-Gabor-Fodor"><a href="#2-7-Gabor-Fodor" class="headerlink" title="2.7 Gábor Fodor"></a>2.7 Gábor Fodor</h2><p><a href="https://www.kaggle.com/gaborfodor">Kaggle—beluga</a></p><p><a href="https://mp.weixin.qq.com/s/3v1LaqwpcfSnFop4hy_jRw">Kaggle GM Gábor：成绩排名说明一切</a></p><h2 id="2-8-柳叶熙"><a href="#2-8-柳叶熙" class="headerlink" title="2.8 柳叶熙"></a>2.8 柳叶熙</h2><p><a href="https://space.bilibili.com/535128436?from=search&seid=14166111367059293020&spm_id_from=333.337.0.0">创壹科技—柳夜熙—bilibili</a></p><h1 id="3-前沿"><a href="#3-前沿" class="headerlink" title="3.前沿"></a>3.前沿</h1><h2 id="3-1-戴琼海-发现、理解与创造"><a href="#3-1-戴琼海-发现、理解与创造" class="headerlink" title="3.1 戴琼海:发现、理解与创造"></a>3.1 戴琼海:发现、理解与创造</h2><p><a href="https://www.cxyinfo.com/cms/show-7366.html">戴琼海院士谈人工智能未来：发现、理解与创造</a></p><h2 id="3-2-CoRL-2021-Awards"><a href="#3-2-CoRL-2021-Awards" class="headerlink" title="3.2 CoRL 2021 Awards"></a>3.2 CoRL 2021 Awards</h2><p><a href="https://www.robot-learning.org/program/awards_2021">CoRL 2021 Awards</a></p><h2 id="3-3-IJCLR-Zhi-Hua-Zhou-“From-Pure-Learning-to-Learning-amp-Reasoning”"><a href="#3-3-IJCLR-Zhi-Hua-Zhou-“From-Pure-Learning-to-Learning-amp-Reasoning”" class="headerlink" title="3.3 IJCLR  Zhi-Hua Zhou: “From Pure Learning to Learning &amp; Reasoning”"></a>3.3 IJCLR  Zhi-Hua Zhou: “From Pure Learning to Learning &amp; Reasoning”</h2><p><a href="http://lr2020.iit.demokritos.gr/">IJCLR</a></p><p><a href="https://www.youtube.com/playlist?list=PL18_rB75vx1PkjXnkX1jiqNeNnVCbNGIh">YouTube—1st International Joint Conference on Learning &amp; Reasonin</a></p><p><a href="https://www.youtube.com/watch?v=LAvRDCcXCMc&list=PL18_rB75vx1PkjXnkX1jiqNeNnVCbNGIh&index=3&ab_channel=Inst.Informatics&Telecomms,NCSRDemokritos">YouTube—IJCLR 2021 Keynote Talk by Zhi-Hua Zhou: “From Pure Learning to Learning &amp; Reasoning”</a></p><h2 id="3-4-UC伯克利—每个神经网络，都是一个高维向量"><a href="#3-4-UC伯克利—每个神经网络，都是一个高维向量" class="headerlink" title="3.4 UC伯克利—每个神经网络，都是一个高维向量"></a>3.4 UC伯克利—每个神经网络，都是一个高维向量</h2><p><a href="https://mp.weixin.qq.com/s/HuM5lHEZYdmZAk8H6r5IRQ">UC伯克利发现「没有免费午餐定理」加强版：每个神经网络，都是一个高维向量—图灵人工智能</a></p><p><a href="https://arxiv.org/abs/2110.03922">Neural Tangent Kernel Eigenvalues Accurately Predict Generalization</a></p><h2 id="3-5-2021深度学习方向—知乎"><a href="#3-5-2021深度学习方向—知乎" class="headerlink" title="3.5 2021深度学习方向—知乎"></a>3.5 2021深度学习方向—知乎</h2><p><a href="https://www.zhihu.com/question/460500204">2021年深度学习哪些方向比较新颖，处于上升期或者朝阳阶段，没那么饱和，比较有研究潜力？—陀飞轮 、Zhifeng 、谢凌曦</a></p><h2 id="3-6-字节跳动—视频抠像工具—RNN"><a href="#3-6-字节跳动—视频抠像工具—RNN" class="headerlink" title="3.6 字节跳动—视频抠像工具—RNN"></a>3.6 字节跳动—视频抠像工具—RNN</h2><p><a href="https://arxiv.org/abs/2108.11515">Robust High-Resolution Video Matting with Temporal Guidance</a></p><p><a href="https://github.com/PeterL1n/RobustVideoMatting">Github源码</a></p><p><a href="https://openbayes.com/console/open-tutorials/containers/oqv42tbd8ko">openbayes</a></p><h2 id="3-7-飞桨图像识别套件PaddleClas"><a href="#3-7-飞桨图像识别套件PaddleClas" class="headerlink" title="3.7 飞桨图像识别套件PaddleClas"></a>3.7 飞桨图像识别套件PaddleClas</h2><p><a href="https://github.com/PaddlePaddle/PaddleClas">PaddleClas—GitHub</a></p><h2 id="3-8-Small-Data’s-Big-AI-Potential"><a href="#3-8-Small-Data’s-Big-AI-Potential" class="headerlink" title="3.8 Small Data’s Big AI Potential"></a>3.8 Small Data’s Big AI Potential</h2><p><a href="https://cset.georgetown.edu/publication/small-datas-big-ai-potential/">Small Data’s Big AI Potential</a></p><p><a href="https://cset.georgetown.edu/">CSTE</a></p><p><a href="https://mp.weixin.qq.com/s/DuEk7II2Th7s9Uyr-bx7WQ">美国智库最新报告：长期被忽略的小数据人工智能潜力不可估量—大数据文摘</a></p><h2 id="3-9-Bilingualism-Comes-Naturally-to-Our-Brains"><a href="#3-9-Bilingualism-Comes-Naturally-to-Our-Brains" class="headerlink" title="3.9 Bilingualism Comes Naturally to Our Brains"></a>3.9 Bilingualism Comes Naturally to Our Brains</h2><p><a href="https://www.eneuro.org/content/8/6/ENEURO.0084-21.2021#sec-10">Paper—Composition within and between Languages in the Bilingual Mind: MEG Evidence from Korean/English Bilinguals</a></p><p><a href="https://www.nyu.edu/about/news-publications/news/2021/november/bilingualism-comes-naturally-to-our-brains.html">NYU—Bilingualism Comes Naturally to Our Brains</a></p><h2 id="3-10-内在触感-强化学习-机械手"><a href="#3-10-内在触感-强化学习-机械手" class="headerlink" title="3.10 内在触感  强化学习  机械手"></a>3.10 内在触感  强化学习  机械手</h2><p><a href="https://arxiv.org/abs/2109.12720">Paper—On the Feasibility of Learning Finger-gaiting In-hand Manipulation with Intrinsic Sensing</a></p><h2 id="3-11-大脑学习算法模型模拟反向传播过程"><a href="#3-11-大脑学习算法模型模拟反向传播过程" class="headerlink" title="3.11 大脑学习算法模型模拟反向传播过程"></a>3.11 大脑学习算法模型模拟反向传播过程</h2><p><a href="https://mp.weixin.qq.com/s/RxZhzYDCuAkxfeOa6v7ySA">大脑学习算法模型模拟反向传播过程</a></p><p><a href="https://www.nature.com/articles/s41593-021-00857-x">Paper—Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits</a></p><p><a href="https://www.quantamagazine.org/brain-bursts-can-mimic-famous-ai-learning-strategy-20211018/">Neuron Bursts Can Mimic Famous AI Learning Strategy</a></p><h1 id="4-学习资源"><a href="#4-学习资源" class="headerlink" title="4.学习资源"></a>4.学习资源</h1><h2 id="4-1-《Statistical-Thinking-for-the-21st-Century》—Stanford-University"><a href="#4-1-《Statistical-Thinking-for-the-21st-Century》—Stanford-University" class="headerlink" title="4.1 《Statistical Thinking for the 21st Century》—Stanford University"></a>4.1 《Statistical Thinking for the 21st Century》—Stanford University</h2><p><a href="https://statsthinking21.github.io/statsthinking21-core-site/">《Statistical Thinking for the 21st Century》</a></p><p><a href="https://github.com/statsthinking21/statsthinking21-core">statsthinking21—Github</a></p><h2 id="4-2-C语言入门笔记"><a href="#4-2-C语言入门笔记" class="headerlink" title="4.2 C语言入门笔记"></a>4.2 C语言入门笔记</h2><p><a href="https://mp.weixin.qq.com/s/-w5lbR4awV-JQQtTGWjylA">C语言最全入门笔记—图灵人工智能</a></p><h2 id="4-3-简单的机器学习模型线性回归"><a href="#4-3-简单的机器学习模型线性回归" class="headerlink" title="4.3 简单的机器学习模型线性回归"></a>4.3 简单的机器学习模型线性回归</h2><p><a href="https://mp.weixin.qq.com/s/n7gjNYEMUFzJuCxuZ47zgQ">初学者指南：使用 Numpy、Keras 和 PyTorch 实现最简单的机器学习模型线性回归—数据派THU</a></p><p><a href="https://github.com/Motamensalih/Simple-Linear-Regression">Simple-Linear-Regression—Github</a></p><h2 id="4-4-17个机器学习的常用算法！"><a href="#4-4-17个机器学习的常用算法！" class="headerlink" title="4.4 17个机器学习的常用算法！"></a>4.4 17个机器学习的常用算法！</h2><p><a href="https://mp.weixin.qq.com/s/PTdArpfF2n9JtgJbmS1G6A">17个机器学习的常用算法！—图灵人工智能</a></p><h2 id="4-5-鱼水说竞赛：竞赛模型选择"><a href="#4-5-鱼水说竞赛：竞赛模型选择" class="headerlink" title="4.5 鱼水说竞赛：竞赛模型选择"></a>4.5 鱼水说竞赛：竞赛模型选择</h2><p><a href="https://mp.weixin.qq.com/s/E-g7faR0AUGstdNMzVnlkw">鱼水说竞赛：竞赛模型选择</a></p><h2 id="4-6-计算机早期历史-Early-Computing"><a href="#4-6-计算机早期历史-Early-Computing" class="headerlink" title="4.6 计算机早期历史-Early Computing"></a>4.6 计算机早期历史-Early Computing</h2><p><a href="https://www.youtube.com/watch?v=WqrNphu6HaU&ab_channel=%E8%B8%8F%E9%9B%AA%E6%97%A0%E7%97%95">计算机早期历史-Early Computing–YouTube</a></p><h2 id="4-7-图神经网络科普"><a href="#4-7-图神经网络科普" class="headerlink" title="4.7 图神经网络科普"></a>4.7 图神经网络科普</h2><p><a href="https://mp.weixin.qq.com/s/nIKHmgTJQU3pyQzaxmuVhw">图神经网络科普</a></p><p><a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</a></p><p><a href="https://distill.pub/2021/understanding-gnns/">Understanding Convolutions on Graphs</a></p><h2 id="4-8-《Mathematical-Foundations-for-Data-Analysis》"><a href="#4-8-《Mathematical-Foundations-for-Data-Analysis》" class="headerlink" title="4.8 《Mathematical Foundations for Data Analysis》"></a>4.8 《Mathematical Foundations for Data Analysis》</h2><p><a href="https://mathfordata.github.io/">《Mathematical Foundations for Data Analysis》—Jeff M. Phillips</a></p><h1 id="5-职场"><a href="#5-职场" class="headerlink" title="5.职场"></a>5.职场</h1><h2 id="5-1-博士-入职-三四流高校-参考意见—知乎"><a href="#5-1-博士-入职-三四流高校-参考意见—知乎" class="headerlink" title="5.1 博士  入职  三四流高校  参考意见—知乎"></a>5.1 博士  入职  三四流高校  参考意见—知乎</h2><p><a href="https://mp.weixin.qq.com/s/Nz_GpKHNQ-1sqFp3vRMt2w">博士  入职  三四线高校  参考意见—图灵人工智能</a></p><h1 id="6-机构、网站"><a href="#6-机构、网站" class="headerlink" title="6.机构、网站"></a>6.机构、网站</h1><h2 id="6-1-北京智源人工智能研究院"><a href="#6-1-北京智源人工智能研究院" class="headerlink" title="6.1 北京智源人工智能研究院"></a>6.1 北京智源人工智能研究院</h2><p><a href="https://www.baai.ac.cn/">北京智源人工智能研究院</a></p><h2 id="6-2-FAIR"><a href="#6-2-FAIR" class="headerlink" title="6.2 FAIR"></a>6.2 FAIR</h2><p><a href="https://ai.facebook.com/">FAIR</a></p><h2 id="6-3-CZ-Biohub"><a href="#6-3-CZ-Biohub" class="headerlink" title="6.3 CZ Biohub"></a>6.3 CZ Biohub</h2><p><a href="https://www.czbiohub.org/">CZ Biohub</a></p><h1 id="7-数据集"><a href="#7-数据集" class="headerlink" title="7.数据集"></a>7.数据集</h1><h2 id="7-1-MedMNIST"><a href="#7-1-MedMNIST" class="headerlink" title="7.1 MedMNIST"></a>7.1 MedMNIST</h2><p>MedMNIST:A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification</p><p><a href="https://medmnist.com/">MedMNIST v2</a></p><p><a href="https://github.com/MedMNIST/MedMNIST">MedMNIST—GitHub</a></p><p><a href="https://arxiv.org/pdf/2110.14795.pdf">MedMNIST v2论文</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>EDG我们是冠军！</title>
      <link href="/2021/11/07/EDG%E6%88%91%E4%BB%AC%E6%98%AF%E5%86%A0%E5%86%9B/"/>
      <url>/2021/11/07/EDG%E6%88%91%E4%BB%AC%E6%98%AF%E5%86%A0%E5%86%9B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>EDG！ 我们是冠军！<br>Make/Break!<br>不破不立！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>11月3日文章分享</title>
      <link href="/2021/11/03/11%E6%9C%883%E6%97%A5%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"/>
      <url>/2021/11/03/11%E6%9C%883%E6%97%A5%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="1-演讲"><a href="#1-演讲" class="headerlink" title="1.演讲"></a>1.演讲</h1><h2 id="1-1-John-Edward-Hopcroft-《开放科学：科学传播与人才培养》"><a href="#1-1-John-Edward-Hopcroft-《开放科学：科学传播与人才培养》" class="headerlink" title="1.1 John Edward Hopcroft 《开放科学：科学传播与人才培养》"></a>1.1 John Edward Hopcroft 《开放科学：科学传播与人才培养》</h2><p><a href="https://new.qq.com/omn/20211102/20211102A02F6400.html">图灵奖得主：中国应该重视本科教育质量，而不是研究经费和论文数量-腾讯网</a></p><h1 id="2-人物"><a href="#2-人物" class="headerlink" title="2.人物"></a>2.人物</h1><h2 id="2-1-John-Edward-Hopcroft："><a href="#2-1-John-Edward-Hopcroft：" class="headerlink" title="2.1 John Edward Hopcroft："></a>2.1 John Edward Hopcroft：</h2><p><a href="https://news.sjtu.edu.cn/mtjj/20180405/67002.html">图灵奖获得者约翰·霍普克罗夫特：中国高校必须教会学生提问—上海交通大学新闻学术网</a></p><p><a href="http://zqb.cyol.com/html/2012-02/09/nw.D110000zgqnb_20120209_3-03.htm">中国高校必须教会学生提问—中国青年报</a></p><h2 id="2-2-吴天齐"><a href="#2-2-吴天齐" class="headerlink" title="2.2 吴天齐"></a>2.2 吴天齐</h2><p><a href="https://mp.weixin.qq.com/s/TzkUvWwksCjQcvmRYh8Odw">吴齐天的科研思考—DataWhale</a></p><p><a href="https://thinklab.sjtu.edu.cn/">SJTU-ThinkLab官网</a></p><h2 id="2-3-Johnson-Kuan"><a href="#2-3-Johnson-Kuan" class="headerlink" title="2.3 Johnson Kuan"></a>2.3 Johnson Kuan</h2><p><a href="https://towardsdatascience.com/how-i-won-andrew-ngs-very-first-data-centric-ai-competition-e02001268bda">Johnson Kuan：How I Won Andrew Ng’s First Data-Centric AI Competition</a></p><h2 id="2-4-陶中恺"><a href="#2-4-陶中恺" class="headerlink" title="2.4 陶中恺"></a>2.4 陶中恺</h2><p><a href="https://mp.weixin.qq.com/s/5245h0CMA45h8ONNflzb6Q">阿里数学竞赛最年轻金奖得主陶中恺：“学数学还是要自信”</a></p><h1 id="3-新闻"><a href="#3-新闻" class="headerlink" title="3.新闻"></a>3.新闻</h1><h2 id="3-1-VMware-与戴尔正式“分手”"><a href="#3-1-VMware-与戴尔正式“分手”" class="headerlink" title="3.1 VMware 与戴尔正式“分手”"></a>3.1 VMware 与戴尔正式“分手”</h2><p><a href="https://blog.csdn.net/sinat_14921509/article/details/121097972?spm=1000.2115.3001.5927">VMware 与戴尔正式“分手”—苏小宓的CSDN</a></p><p><a href="https://news.vmware.com/leadership/ceo-raghu-raghuram-spin-off-complete">The Start of a New Era for VMware</a></p><h2 id="3-2-ReSkin"><a href="#3-2-ReSkin" class="headerlink" title="3.2 ReSkin"></a>3.2 ReSkin</h2><p><a href="https://ai.facebook.com/blog/reskin-a-versatile-replaceable-low-cost-skin-for-ai-research-on-tactile-perception/">ReSkin: a versatile, replaceable, low-cost skin for AI research on tactile perception</a></p><h1 id="4-实用网站"><a href="#4-实用网站" class="headerlink" title="4.实用网站"></a>4.实用网站</h1><h2 id="4-1-GitHub最大的开源算法库—The-Algorithms"><a href="#4-1-GitHub最大的开源算法库—The-Algorithms" class="headerlink" title="4.1 GitHub最大的开源算法库—The Algorithms"></a>4.1 GitHub最大的开源算法库—The Algorithms</h2><p><a href="https://the-algorithms.com/">The Algorithms</a></p><p><a href="https://github.com/TheAlgorithms">The Algorithms’s GitHub</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>决赛见！</title>
      <link href="/2021/11/01/%E5%86%B3%E8%B5%9B%E8%A7%81/"/>
      <url>/2021/11/01/%E5%86%B3%E8%B5%9B%E8%A7%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【Colab】基本操作【LeNet】【MNIST】训练测试</title>
      <link href="/2021/10/31/Colab+LeNet+MNIST/"/>
      <url>/2021/10/31/Colab+LeNet+MNIST/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><a href="https://colab.research.google.com/notebooks/welcome.ipynb">Colab 官网初始界面</a></p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h1><p><a href="https://developer.nvidia.com/zh-cn/cuda-gpus">英伟达官网</a><br>谷歌将原来K80换成了T4<br><img src="https://img-blog.csdnimg.cn/7975074e2ece4cdc8be72e96851fd996.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="2-查看基本配置"><a href="#2-查看基本配置" class="headerlink" title="2.查看基本配置"></a>2.查看基本配置</h1><h3 id="2-1查看pytorch版本"><a href="#2-1查看pytorch版本" class="headerlink" title="2.1查看pytorch版本"></a>2.1查看pytorch版本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b08a271c94da4d0293ac0dbc8ff3cc25.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_13,color_FFFFFF,t_70,g_se,x_16"></p><h3 id="2-2查看是否可以使用cuda"><a href="#2-2查看是否可以使用cuda" class="headerlink" title="2.2查看是否可以使用cuda"></a>2.2查看是否可以使用cuda</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/cce0d37208584800922981b38136b11f.png"><br>修改-&gt;笔记本设置-&gt;GPU<br><img src="https://img-blog.csdnimg.cn/38bcb5ea6f724e1a8a120bd71614efcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_19,color_FFFFFF,t_70,g_se,x_16"></p><h3 id="2-3查看显卡配置"><a href="#2-3查看显卡配置" class="headerlink" title="2.3查看显卡配置"></a>2.3查看显卡配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line">//注意英文感叹号</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a222ea06ae0c44ce8f34592494dca1c3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="3-挂载"><a href="#3-挂载" class="headerlink" title="3.挂载"></a>3.挂载</h1><h3 id="31-挂载谷歌云盘"><a href="#31-挂载谷歌云盘" class="headerlink" title="31.挂载谷歌云盘"></a>31.挂载谷歌云盘</h3><p>Colab的运行原理实际上就是给你分配一台远程的带GPU的主机，所以它的原始路径不是你的谷歌云盘（也就是你的代码文件）所在的路径。所以第一步我们先要把谷歌云盘挂载带到那台远程主机上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&quot;/content/drive&quot;</span>)</span><br></pre></td></tr></table></figure><p>登录谷歌账号并将验证码粘到框中</p><h3 id="3-2更改运行目录"><a href="#3-2更改运行目录" class="headerlink" title="3.2更改运行目录"></a>3.2更改运行目录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;/content/drive/MyDrive/Colab Notebooks/LeNet_MNIST_train_test&quot;</span>)</span><br></pre></td></tr></table></figure><p>下面是我的目录结构<br><img src="https://img-blog.csdnimg.cn/a96be368c2ef4298af8e0fae94d4f61d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="4-训练"><a href="#4-训练" class="headerlink" title="4.训练"></a>4.训练</h1><p>【LeNet】+【MNIST】</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>),</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        output = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">train_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    dataset=train_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">test_dataloader = DataLoader(</span><br><span class="line">    dataset=test_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_datasets_size = <span class="built_in">len</span>(train_datasets)</span><br><span class="line">test_datasets_size = <span class="built_in">len</span>(test_datasets)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_datasets_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_datasets_size))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">runing_mode = <span class="string">&quot;gpu&quot;</span> <span class="comment"># cpu,gpu, gpus</span></span><br><span class="line"><span class="keyword">if</span> runing_mode == <span class="string">&quot;gpu&quot;</span> <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cuda&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cpu&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = LeNet()</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss_fn.to(device)</span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">epoch = <span class="number">10</span></span><br><span class="line">train_step, test_step = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;~~~~~~~~~~~~第&#123;&#125;轮训练开始~~~~~~~~~~~&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    start = time.time()</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">        output = model(imgs)</span><br><span class="line">        loss = loss_fn(output, targets)</span><br><span class="line"></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line"></span><br><span class="line">        train_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> train_step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;次训练，loss=&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(train_step, loss.item()))</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        test_loss, true_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">            output = model(imgs)</span><br><span class="line">            test_loss += loss_fn(output, targets)</span><br><span class="line">            true_num += (output.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;轮测试集上的loss:&#123;:.3f&#125;, 正确率为:&#123;:.3f&#125;%,耗时:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(test_step+<span class="number">1</span>, test_loss.item(), <span class="number">100</span> * true_num / test_datasets_size, end-start))</span><br><span class="line">    test_step += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>运行结果：<br>1.CPU<br><img src="https://img-blog.csdnimg.cn/14edcf10c0d446a189f4a6fc44fba1ce.png"><br>2.GPU<br><img src="https://img-blog.csdnimg.cn/f396f9c673a24d719516dd5abc055ba1.png"></p><h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5.Reference"></a>5.Reference</h1><p><a href="https://blog.csdn.net/u010881576/article/details/120919330">《Colab使用训练指南》 坚强的羊脂球</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>10月文章分享</title>
      <link href="/2021/10/30/10%E6%9C%88%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"/>
      <url>/2021/10/30/10%E6%9C%88%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="1-演讲"><a href="#1-演讲" class="headerlink" title="1.演讲"></a>1.演讲</h1><h2 id="1-1Steven-Chu：Life-is-too-short-to-go-through-it-without-caring-deeply-about-something"><a href="#1-1Steven-Chu：Life-is-too-short-to-go-through-it-without-caring-deeply-about-something" class="headerlink" title="1.1Steven Chu：Life is too short to go through it without caring deeply about something."></a>1.1Steven Chu：Life is too short to go through it without caring deeply about something.</h2><p><a href="https://news.harvard.edu/gazette/story/2009/06/u-s-energy-secretary-steven-chus-address-at-harvards-afternoon-exercises/">Stenven Chu in_Harvard Commencement 2009</a></p><p><a href="https://ruanyifeng.com/blog/2009/06/remarks_of_stenven_chu_in_harvard_commencement_2009.html">ruanyifeng’s blog:Remarks of Stenven Chu in harvard commencement</a></p><h2 id="1-2李彦宏：创新、跨界、开放的新工科人才"><a href="#1-2李彦宏：创新、跨界、开放的新工科人才" class="headerlink" title="1.2李彦宏：创新、跨界、开放的新工科人才"></a>1.2李彦宏：创新、跨界、开放的新工科人才</h2><p><a href="http://www.pku.org.cn/people/xyjy/1350143.htm">1987级校友李彦宏在北大新工科国际论坛上的演讲</a></p><h2 id="1-3丘成桐-中学数学教育"><a href="#1-3丘成桐-中学数学教育" class="headerlink" title="1.3丘成桐 中学数学教育"></a>1.3丘成桐 中学数学教育</h2><p><a href="https://blog.csdn.net/FnqTyr45/article/details/80490984">丘成桐：中国学生基础真的比欧美学生好吗？</a></p><p>ps：找了一些相同内容的文章，标题太刺眼，感谢这位博主的文章~</p><h1 id="2-人物"><a href="#2-人物" class="headerlink" title="2.人物"></a>2.人物</h1><h2 id="2-1-Klaus-Hasselmann：I-did-not-have-a-real-supervisor"><a href="#2-1-Klaus-Hasselmann：I-did-not-have-a-real-supervisor" class="headerlink" title="2.1 Klaus Hasselmann：I did not have a real supervisor"></a>2.1 Klaus Hasselmann：I did not have a real supervisor</h2><p><a href="https://www.aip.org/history-programs/niels-bohr-library/oral-histories/33645">Oral History Interviews about Klaus Hasselmann on February 15, 2006</a></p><h2 id="2-2-施一公-如何做一名优秀的博士生？"><a href="#2-2-施一公-如何做一名优秀的博士生？" class="headerlink" title="2.2 施一公 如何做一名优秀的博士生？"></a>2.2 施一公 如何做一名优秀的博士生？</h2><p><a href="http://blog.sciencenet.cn/blog-46212-484416.html">（一）时间的付出</a></p><p><a href="http://blog.sciencenet.cn/blog-46212-486270.html">（二）方法论的转变</a></p><h2 id="2-3-Matt-Might：10-easy-ways-to-fail-a-Ph-D"><a href="#2-3-Matt-Might：10-easy-ways-to-fail-a-Ph-D" class="headerlink" title="2.3 Matt Might：10 easy ways to fail a Ph.D."></a>2.3 Matt Might：10 easy ways to fail a Ph.D.</h2><p><a href="https://matt.might.net/articles/ways-to-fail-a-phd/">Matt Might：ways to fail a Ph.D.</a></p><h2 id="2-4-跟李沐学AI"><a href="#2-4-跟李沐学AI" class="headerlink" title="2.4 跟李沐学AI"></a>2.4 跟李沐学AI</h2><p><a href="https://www.bilibili.com/read/cv13335461/">李沐：用随机梯度下降来优化人生</a></p><p>沐神的b站：<a href="https://space.bilibili.com/1567748478">跟李沐学AI</a></p><h2 id="2-5-LShang001"><a href="#2-5-LShang001" class="headerlink" title="2.5 LShang001"></a>2.5 LShang001</h2><p>LShang001的b站：<a href="https://i0.hdslb.com/bfs/space/cb1c3ef50e22b6096fde67febe863494caefebad.png">LShang001</a></p><h2 id="2-6-稚晖君"><a href="#2-6-稚晖君" class="headerlink" title="2.6 稚晖君"></a>2.6 稚晖君</h2><p>稚晖君的b站：<a href="https://space.bilibili.com/20259914?from=search&seid=1336220716890113133&spm_id_from=333.337.0.0">稚晖君</a></p><p>稚晖君的Github：<a href="https://github.com/peng-zhihui">稚晖</a></p><h2 id="2-7-张焕晨-读博，你真的想好了吗？"><a href="#2-7-张焕晨-读博，你真的想好了吗？" class="headerlink" title="2.7 张焕晨 读博，你真的想好了吗？"></a>2.7 张焕晨 读博，你真的想好了吗？</h2><p><a href="https://zhuanlan.zhihu.com/p/372884253">张焕晨：读博，你真的想好了吗？</a></p><p>ps：根据个人需求有选择地阅读，尽量不要受到他人评论影响~</p><h1 id="3-前沿新闻"><a href="#3-前沿新闻" class="headerlink" title="3.前沿新闻"></a>3.前沿新闻</h1><h2 id="3-1-Ghost-Robotics-CEO-Jiren-Parikh：If-our-robot-had-tracks-on-it-instead-of-legs-nobody-would-be-paying-attention"><a href="#3-1-Ghost-Robotics-CEO-Jiren-Parikh：If-our-robot-had-tracks-on-it-instead-of-legs-nobody-would-be-paying-attention" class="headerlink" title="3.1 Ghost Robotics CEO Jiren Parikh：If our robot had tracks on it instead of legs, nobody would be paying attention."></a>3.1 Ghost Robotics CEO Jiren Parikh：If our robot had tracks on it instead of legs, nobody would be paying attention.</h2><p><a href="https://spectrum.ieee.org/ghost-robotics-armed-military-robots">Interview with Jiren Parikh, CEO of Ghost Robotics by IEEE Spectrum.</a></p><h2 id="3-2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）"><a href="#3-2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）" class="headerlink" title="3.2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）"></a>3.2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）</h2><p><a href="https://www.science.org/doi/10.1126/sciadv.abh0146">Self-backpropagation of synaptic modifications elevates the efficiency of spiking and artificial neural networks</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>这篇博客的诞生</title>
      <link href="/2021/10/30/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
      <url>/2021/10/30/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><a href="https://blog.csdn.net/weixin_52034760/article/details/121047628">Hexo+Github搭建blog</a></p><p>这里为了不熟悉Markdown语法，挂上官方连接：<br><a href="https://markdown.com.cn/basic-syntax/">Markdown基本语法</a></p><p>02 Apr，2021&lt;<br>1.小白<br>2.不适应Shell<br>3.不了解Markdown及HTML</p><p>30 Oct，2021<br>1.逐渐适应Shell<br>2.Markdown基础语法<br>3.Git原理未了解<br>4.GitHub使用增多，Gist、论文源代码、开源项目（少）<br>5.SSH原理未了解<br>6.URL原理未了解<br>7.Github中的master暂未了解<br>8.默认主题</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
