<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>11月3日-11月14日文章分享</title>
      <link href="/2021/11/15/11%E6%9C%883%E6%97%A5-11%E6%9C%8814%E6%97%A5%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/"/>
      <url>/2021/11/15/11%E6%9C%883%E6%97%A5-11%E6%9C%8814%E6%97%A5%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<p>@[TOC]</p><h1 id="1-教育"><a href="#1-教育" class="headerlink" title="1.教育"></a>1.教育</h1><h2 id="1-1-Albert-Einstein"><a href="#1-1-Albert-Einstein" class="headerlink" title="1.1 Albert Einstein"></a>1.1 Albert Einstein</h2><p><a href="https://new.qq.com/omn/20210202/20210202A031QZ00.html">爱因斯坦：教育的首要目标是什么？—腾讯新闻</a></p><h2 id="1-2-论学术与学术标准—李伯重"><a href="#1-2-论学术与学术标准—李伯重" class="headerlink" title="1.2 论学术与学术标准—李伯重"></a>1.2 论学术与学术标准—李伯重</h2><p><a href="https://www.cnki.net/KCMS/detail/detail.aspx?filename=SKLU200503001&dbname=cjfdtotal&dbcode=CJFD&v=MDk5NjFpYkhlN0c0SHRUTXJJOUZaWVI2RGc4L3poWVU3enNPVDNpUXJSY3pGckNVUjd1ZVp1ZHFGQ3JsVjc3QU4=">论学术与学术标准—李伯重</a></p><h2 id="1-3-康毅滨"><a href="#1-3-康毅滨" class="headerlink" title="1.3 康毅滨"></a>1.3 康毅滨</h2><p><a href="https://mp.weixin.qq.com/s/tYg3wwxJxPNrK7g4L3DRWg">《星期日新闻晨报》康毅滨访谈</a></p><h2 id="1-4-亲子教育"><a href="#1-4-亲子教育" class="headerlink" title="1.4 亲子教育"></a>1.4 亲子教育</h2><p><a href="https://mp.weixin.qq.com/s/EC2RzHZ_d4nR85Vs7x-6UA">100幅心理漫画告诉我们：教育可以很简单</a></p><h1 id="2-人物"><a href="#2-人物" class="headerlink" title="2.人物"></a>2.人物</h1><h2 id="2-1-清华大学本科生特等奖学金答辩"><a href="#2-1-清华大学本科生特等奖学金答辩" class="headerlink" title="2.1 清华大学本科生特等奖学金答辩"></a>2.1 清华大学本科生特等奖学金答辩</h2><p><a href="https://www.tsinghua.edu.cn/info/1181/88823.htm">2021年清华大学本科生特等奖学金答辩会举行</a></p><h2 id="2-2-John-von-Neumann"><a href="#2-2-John-von-Neumann" class="headerlink" title="2.2 John von Neumann"></a>2.2 John von Neumann</h2><p><a href="https://www.cantorsparadise.com/the-unparalleled-genius-of-john-von-neumann-791bb9f42a2d">The Unparalleled Genius of John von Neumann—Jørgen Veisdal</a></p><h2 id="2-3-华科团队EDA全球冠军"><a href="#2-3-华科团队EDA全球冠军" class="headerlink" title="2.3 华科团队EDA全球冠军"></a>2.3 华科团队EDA全球冠军</h2><p><a href="http://iccad-contest.org/2021/Problems.html">CAD Contest</a></p><p><a href="http://iccad-contest.org/2021/ProblemB-cada0136.mp4">华科团队EDA全球冠军解决方案mp4</a></p><h2 id="2-4-Jure-Leskovec"><a href="#2-4-Jure-Leskovec" class="headerlink" title="2.4 Jure Leskovec"></a>2.4 Jure Leskovec</h2><p>研究方向:<br>applied machine learning for large interconnected systems focusing on modeling complex, richly-labeled relational structures, graphs, and networks for systems at all scales, from interactions of proteins in a cell to interactions between humans in a society. Applications include commonsense reasoning, recommender systems, computational social science, and computational biology with an emphasis on drug discovery.</p><p><a href="https://cs.stanford.edu/people/jure/">Jure Leskovec  @  Stanford</a></p><p><a href="https://arxiv.org/abs/1810.00826#">Paper—How Powerful are Graph Neural Networks?</a></p><p><a href="https://static.aminer.cn/misc/pdf/graphsage2-mit-nov19.pdf">Jure Leskovec清华演讲PPT—AMiner</a></p><h2 id="2-5-Yann-LeCun"><a href="#2-5-Yann-LeCun" class="headerlink" title="2.5 Yann LeCun"></a>2.5 Yann LeCun</h2><p><a href="https://www.yicai.com/news/5272525.html">法国极客Yann LeCun：掌舵Facebook人工智能 | 完美人物志</a></p><p><a href="https://www.leiphone.com/category/ai/62TcDCKFomfCEWnQ.html">Yann LeCun专访：我不觉得自己有天分，但是我一直往聪明人堆里钻</a></p><h2 id="2-6-何恺明"><a href="#2-6-何恺明" class="headerlink" title="2.6 何恺明"></a>2.6 何恺明</h2><p><a href="http://kaiminghe.com/">Kaiming He</a></p><p><a href="https://arxiv.org/abs/2111.06377">Masked Autoencoders Are Scalable Vision Learners</a></p><p><a href="https://ai.facebook.com/">FAIR</a></p><h2 id="2-7-Gabor-Fodor"><a href="#2-7-Gabor-Fodor" class="headerlink" title="2.7 Gábor Fodor"></a>2.7 Gábor Fodor</h2><p><a href="https://www.kaggle.com/gaborfodor">Kaggle—beluga</a></p><p><a href="https://mp.weixin.qq.com/s/3v1LaqwpcfSnFop4hy_jRw">Kaggle GM Gábor：成绩排名说明一切</a></p><h2 id="2-8-柳叶熙"><a href="#2-8-柳叶熙" class="headerlink" title="2.8 柳叶熙"></a>2.8 柳叶熙</h2><p><a href="https://space.bilibili.com/535128436?from=search&seid=14166111367059293020&spm_id_from=333.337.0.0">创壹科技—柳夜熙—bilibili</a></p><h1 id="3-前沿"><a href="#3-前沿" class="headerlink" title="3.前沿"></a>3.前沿</h1><h2 id="3-1-戴琼海-发现、理解与创造"><a href="#3-1-戴琼海-发现、理解与创造" class="headerlink" title="3.1 戴琼海:发现、理解与创造"></a>3.1 戴琼海:发现、理解与创造</h2><p><a href="https://www.cxyinfo.com/cms/show-7366.html">戴琼海院士谈人工智能未来：发现、理解与创造</a></p><h2 id="3-2-CoRL-2021-Awards"><a href="#3-2-CoRL-2021-Awards" class="headerlink" title="3.2 CoRL 2021 Awards"></a>3.2 CoRL 2021 Awards</h2><p><a href="https://www.robot-learning.org/program/awards_2021">CoRL 2021 Awards</a></p><h2 id="3-3-IJCLR-Zhi-Hua-Zhou-“From-Pure-Learning-to-Learning-amp-Reasoning”"><a href="#3-3-IJCLR-Zhi-Hua-Zhou-“From-Pure-Learning-to-Learning-amp-Reasoning”" class="headerlink" title="3.3 IJCLR  Zhi-Hua Zhou: “From Pure Learning to Learning &amp; Reasoning”"></a>3.3 IJCLR  Zhi-Hua Zhou: “From Pure Learning to Learning &amp; Reasoning”</h2><p><a href="http://lr2020.iit.demokritos.gr/">IJCLR</a></p><p><a href="https://www.youtube.com/playlist?list=PL18_rB75vx1PkjXnkX1jiqNeNnVCbNGIh">YouTube—1st International Joint Conference on Learning &amp; Reasonin</a></p><p><a href="https://www.youtube.com/watch?v=LAvRDCcXCMc&list=PL18_rB75vx1PkjXnkX1jiqNeNnVCbNGIh&index=3&ab_channel=Inst.Informatics&Telecomms,NCSRDemokritos">YouTube—IJCLR 2021 Keynote Talk by Zhi-Hua Zhou: “From Pure Learning to Learning &amp; Reasoning”</a></p><h2 id="3-4-UC伯克利—每个神经网络，都是一个高维向量"><a href="#3-4-UC伯克利—每个神经网络，都是一个高维向量" class="headerlink" title="3.4 UC伯克利—每个神经网络，都是一个高维向量"></a>3.4 UC伯克利—每个神经网络，都是一个高维向量</h2><p><a href="https://mp.weixin.qq.com/s/HuM5lHEZYdmZAk8H6r5IRQ">UC伯克利发现「没有免费午餐定理」加强版：每个神经网络，都是一个高维向量—图灵人工智能</a></p><p><a href="https://arxiv.org/abs/2110.03922">Neural Tangent Kernel Eigenvalues Accurately Predict Generalization</a></p><h2 id="3-5-2021深度学习方向—知乎"><a href="#3-5-2021深度学习方向—知乎" class="headerlink" title="3.5 2021深度学习方向—知乎"></a>3.5 2021深度学习方向—知乎</h2><p><a href="https://www.zhihu.com/question/460500204">2021年深度学习哪些方向比较新颖，处于上升期或者朝阳阶段，没那么饱和，比较有研究潜力？—陀飞轮 、Zhifeng 、谢凌曦</a></p><h2 id="3-6-字节跳动—视频抠像工具—RNN"><a href="#3-6-字节跳动—视频抠像工具—RNN" class="headerlink" title="3.6 字节跳动—视频抠像工具—RNN"></a>3.6 字节跳动—视频抠像工具—RNN</h2><p><a href="https://arxiv.org/abs/2108.11515">Robust High-Resolution Video Matting with Temporal Guidance</a></p><p><a href="https://github.com/PeterL1n/RobustVideoMatting">Github源码</a></p><p><a href="https://openbayes.com/console/open-tutorials/containers/oqv42tbd8ko">openbayes</a></p><h2 id="3-7-飞桨图像识别套件PaddleClas"><a href="#3-7-飞桨图像识别套件PaddleClas" class="headerlink" title="3.7 飞桨图像识别套件PaddleClas"></a>3.7 飞桨图像识别套件PaddleClas</h2><p><a href="https://github.com/PaddlePaddle/PaddleClas">PaddleClas—GitHub</a></p><h2 id="3-8-Small-Data’s-Big-AI-Potential"><a href="#3-8-Small-Data’s-Big-AI-Potential" class="headerlink" title="3.8 Small Data’s Big AI Potential"></a>3.8 Small Data’s Big AI Potential</h2><p><a href="https://cset.georgetown.edu/publication/small-datas-big-ai-potential/">Small Data’s Big AI Potential</a></p><p><a href="https://cset.georgetown.edu/">CSTE</a></p><p><a href="https://mp.weixin.qq.com/s/DuEk7II2Th7s9Uyr-bx7WQ">美国智库最新报告：长期被忽略的小数据人工智能潜力不可估量—大数据文摘</a></p><h2 id="3-9-Bilingualism-Comes-Naturally-to-Our-Brains"><a href="#3-9-Bilingualism-Comes-Naturally-to-Our-Brains" class="headerlink" title="3.9 Bilingualism Comes Naturally to Our Brains"></a>3.9 Bilingualism Comes Naturally to Our Brains</h2><p><a href="https://www.eneuro.org/content/8/6/ENEURO.0084-21.2021#sec-10">Paper—Composition within and between Languages in the Bilingual Mind: MEG Evidence from Korean/English Bilinguals</a></p><p><a href="https://www.nyu.edu/about/news-publications/news/2021/november/bilingualism-comes-naturally-to-our-brains.html">NYU—Bilingualism Comes Naturally to Our Brains</a></p><h2 id="3-10-内在触感-强化学习-机械手"><a href="#3-10-内在触感-强化学习-机械手" class="headerlink" title="3.10 内在触感  强化学习  机械手"></a>3.10 内在触感  强化学习  机械手</h2><p><a href="https://arxiv.org/abs/2109.12720">Paper—On the Feasibility of Learning Finger-gaiting In-hand Manipulation with Intrinsic Sensing</a></p><h2 id="3-11-大脑学习算法模型模拟反向传播过程"><a href="#3-11-大脑学习算法模型模拟反向传播过程" class="headerlink" title="3.11 大脑学习算法模型模拟反向传播过程"></a>3.11 大脑学习算法模型模拟反向传播过程</h2><p><a href="https://mp.weixin.qq.com/s/RxZhzYDCuAkxfeOa6v7ySA">大脑学习算法模型模拟反向传播过程</a></p><p><a href="https://www.nature.com/articles/s41593-021-00857-x">Paper—Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits</a></p><p><a href="https://www.quantamagazine.org/brain-bursts-can-mimic-famous-ai-learning-strategy-20211018/">Neuron Bursts Can Mimic Famous AI Learning Strategy</a></p><h1 id="4-学习资源"><a href="#4-学习资源" class="headerlink" title="4.学习资源"></a>4.学习资源</h1><h2 id="4-1-《Statistical-Thinking-for-the-21st-Century》—Stanford-University"><a href="#4-1-《Statistical-Thinking-for-the-21st-Century》—Stanford-University" class="headerlink" title="4.1 《Statistical Thinking for the 21st Century》—Stanford University"></a>4.1 《Statistical Thinking for the 21st Century》—Stanford University</h2><p><a href="https://statsthinking21.github.io/statsthinking21-core-site/">《Statistical Thinking for the 21st Century》</a></p><p><a href="https://github.com/statsthinking21/statsthinking21-core">statsthinking21—Github</a></p><h2 id="4-2-C语言入门笔记"><a href="#4-2-C语言入门笔记" class="headerlink" title="4.2 C语言入门笔记"></a>4.2 C语言入门笔记</h2><p><a href="https://mp.weixin.qq.com/s/-w5lbR4awV-JQQtTGWjylA">C语言最全入门笔记—图灵人工智能</a></p><h2 id="4-3-简单的机器学习模型线性回归"><a href="#4-3-简单的机器学习模型线性回归" class="headerlink" title="4.3 简单的机器学习模型线性回归"></a>4.3 简单的机器学习模型线性回归</h2><p><a href="https://mp.weixin.qq.com/s/n7gjNYEMUFzJuCxuZ47zgQ">初学者指南：使用 Numpy、Keras 和 PyTorch 实现最简单的机器学习模型线性回归—数据派THU</a></p><p><a href="https://github.com/Motamensalih/Simple-Linear-Regression">Simple-Linear-Regression—Github</a></p><h2 id="4-4-17个机器学习的常用算法！"><a href="#4-4-17个机器学习的常用算法！" class="headerlink" title="4.4 17个机器学习的常用算法！"></a>4.4 17个机器学习的常用算法！</h2><p><a href="https://mp.weixin.qq.com/s/PTdArpfF2n9JtgJbmS1G6A">17个机器学习的常用算法！—图灵人工智能</a></p><h2 id="4-5-鱼水说竞赛：竞赛模型选择"><a href="#4-5-鱼水说竞赛：竞赛模型选择" class="headerlink" title="4.5 鱼水说竞赛：竞赛模型选择"></a>4.5 鱼水说竞赛：竞赛模型选择</h2><p><a href="https://mp.weixin.qq.com/s/E-g7faR0AUGstdNMzVnlkw">鱼水说竞赛：竞赛模型选择</a></p><h2 id="4-6-计算机早期历史-Early-Computing"><a href="#4-6-计算机早期历史-Early-Computing" class="headerlink" title="4.6 计算机早期历史-Early Computing"></a>4.6 计算机早期历史-Early Computing</h2><p><a href="https://www.youtube.com/watch?v=WqrNphu6HaU&ab_channel=%E8%B8%8F%E9%9B%AA%E6%97%A0%E7%97%95">计算机早期历史-Early Computing–YouTube</a></p><h2 id="4-7-图神经网络科普"><a href="#4-7-图神经网络科普" class="headerlink" title="4.7 图神经网络科普"></a>4.7 图神经网络科普</h2><p><a href="https://mp.weixin.qq.com/s/nIKHmgTJQU3pyQzaxmuVhw">图神经网络科普</a></p><p><a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</a></p><p><a href="https://distill.pub/2021/understanding-gnns/">Understanding Convolutions on Graphs</a></p><h2 id="4-8-《Mathematical-Foundations-for-Data-Analysis》"><a href="#4-8-《Mathematical-Foundations-for-Data-Analysis》" class="headerlink" title="4.8 《Mathematical Foundations for Data Analysis》"></a>4.8 《Mathematical Foundations for Data Analysis》</h2><p><a href="https://mathfordata.github.io/">《Mathematical Foundations for Data Analysis》—Jeff M. Phillips</a></p><h1 id="5-职场"><a href="#5-职场" class="headerlink" title="5.职场"></a>5.职场</h1><h2 id="5-1-博士-入职-三四流高校-参考意见—知乎"><a href="#5-1-博士-入职-三四流高校-参考意见—知乎" class="headerlink" title="5.1 博士  入职  三四流高校  参考意见—知乎"></a>5.1 博士  入职  三四流高校  参考意见—知乎</h2><p><a href="https://mp.weixin.qq.com/s/Nz_GpKHNQ-1sqFp3vRMt2w">博士  入职  三四线高校  参考意见—图灵人工智能</a></p><h1 id="6-机构、网站"><a href="#6-机构、网站" class="headerlink" title="6.机构、网站"></a>6.机构、网站</h1><h2 id="6-1-北京智源人工智能研究院"><a href="#6-1-北京智源人工智能研究院" class="headerlink" title="6.1 北京智源人工智能研究院"></a>6.1 北京智源人工智能研究院</h2><p><a href="https://www.baai.ac.cn/">北京智源人工智能研究院</a></p><h2 id="6-2-FAIR"><a href="#6-2-FAIR" class="headerlink" title="6.2 FAIR"></a>6.2 FAIR</h2><p><a href="https://ai.facebook.com/">FAIR</a></p><h2 id="6-3-CZ-Biohub"><a href="#6-3-CZ-Biohub" class="headerlink" title="6.3 CZ Biohub"></a>6.3 CZ Biohub</h2><p><a href="https://www.czbiohub.org/">CZ Biohub</a></p><h1 id="7-数据集"><a href="#7-数据集" class="headerlink" title="7.数据集"></a>7.数据集</h1><h2 id="7-1-MedMNIST"><a href="#7-1-MedMNIST" class="headerlink" title="7.1 MedMNIST"></a>7.1 MedMNIST</h2><p>MedMNIST:A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification</p><p><a href="https://medmnist.com/">MedMNIST v2</a></p><p><a href="https://github.com/MedMNIST/MedMNIST">MedMNIST—GitHub</a></p><p><a href="https://arxiv.org/pdf/2110.14795.pdf">MedMNIST v2论文</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>EDG我们是冠军！</title>
      <link href="/2021/11/07/EDG%E6%88%91%E4%BB%AC%E6%98%AF%E5%86%A0%E5%86%9B/"/>
      <url>/2021/11/07/EDG%E6%88%91%E4%BB%AC%E6%98%AF%E5%86%A0%E5%86%9B/</url>
      
        <content type="html"><![CDATA[<p>EDG！ 我们是冠军！<br>Make/Break!<br>不破不立！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>11月3日文章分享</title>
      <link href="/2021/11/03/11%E6%9C%883%E6%97%A5%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"/>
      <url>/2021/11/03/11%E6%9C%883%E6%97%A5%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="1-演讲"><a href="#1-演讲" class="headerlink" title="1.演讲"></a>1.演讲</h1><h2 id="1-1-John-Edward-Hopcroft-《开放科学：科学传播与人才培养》"><a href="#1-1-John-Edward-Hopcroft-《开放科学：科学传播与人才培养》" class="headerlink" title="1.1 John Edward Hopcroft 《开放科学：科学传播与人才培养》"></a>1.1 John Edward Hopcroft 《开放科学：科学传播与人才培养》</h2><p><a href="https://new.qq.com/omn/20211102/20211102A02F6400.html">图灵奖得主：中国应该重视本科教育质量，而不是研究经费和论文数量-腾讯网</a></p><h1 id="2-人物"><a href="#2-人物" class="headerlink" title="2.人物"></a>2.人物</h1><h2 id="2-1-John-Edward-Hopcroft："><a href="#2-1-John-Edward-Hopcroft：" class="headerlink" title="2.1 John Edward Hopcroft："></a>2.1 John Edward Hopcroft：</h2><p><a href="https://news.sjtu.edu.cn/mtjj/20180405/67002.html">图灵奖获得者约翰·霍普克罗夫特：中国高校必须教会学生提问—上海交通大学新闻学术网</a></p><p><a href="http://zqb.cyol.com/html/2012-02/09/nw.D110000zgqnb_20120209_3-03.htm">中国高校必须教会学生提问—中国青年报</a></p><h2 id="2-2-吴天齐"><a href="#2-2-吴天齐" class="headerlink" title="2.2 吴天齐"></a>2.2 吴天齐</h2><p><a href="https://mp.weixin.qq.com/s/TzkUvWwksCjQcvmRYh8Odw">吴齐天的科研思考—DataWhale</a></p><p><a href="https://thinklab.sjtu.edu.cn/">SJTU-ThinkLab官网</a></p><h2 id="2-3-Johnson-Kuan"><a href="#2-3-Johnson-Kuan" class="headerlink" title="2.3 Johnson Kuan"></a>2.3 Johnson Kuan</h2><p><a href="https://towardsdatascience.com/how-i-won-andrew-ngs-very-first-data-centric-ai-competition-e02001268bda">Johnson Kuan：How I Won Andrew Ng’s First Data-Centric AI Competition</a></p><h2 id="2-4-陶中恺"><a href="#2-4-陶中恺" class="headerlink" title="2.4 陶中恺"></a>2.4 陶中恺</h2><p><a href="https://mp.weixin.qq.com/s/5245h0CMA45h8ONNflzb6Q">阿里数学竞赛最年轻金奖得主陶中恺：“学数学还是要自信”</a></p><h1 id="3-新闻"><a href="#3-新闻" class="headerlink" title="3.新闻"></a>3.新闻</h1><h2 id="3-1-VMware-与戴尔正式“分手”"><a href="#3-1-VMware-与戴尔正式“分手”" class="headerlink" title="3.1 VMware 与戴尔正式“分手”"></a>3.1 VMware 与戴尔正式“分手”</h2><p><a href="https://blog.csdn.net/sinat_14921509/article/details/121097972?spm=1000.2115.3001.5927">VMware 与戴尔正式“分手”—苏小宓的CSDN</a></p><p><a href="https://news.vmware.com/leadership/ceo-raghu-raghuram-spin-off-complete">The Start of a New Era for VMware</a></p><h2 id="3-2-ReSkin"><a href="#3-2-ReSkin" class="headerlink" title="3.2 ReSkin"></a>3.2 ReSkin</h2><p><a href="https://ai.facebook.com/blog/reskin-a-versatile-replaceable-low-cost-skin-for-ai-research-on-tactile-perception/">ReSkin: a versatile, replaceable, low-cost skin for AI research on tactile perception</a></p><h1 id="4-实用网站"><a href="#4-实用网站" class="headerlink" title="4.实用网站"></a>4.实用网站</h1><h2 id="4-1-GitHub最大的开源算法库—The-Algorithms"><a href="#4-1-GitHub最大的开源算法库—The-Algorithms" class="headerlink" title="4.1 GitHub最大的开源算法库—The Algorithms"></a>4.1 GitHub最大的开源算法库—The Algorithms</h2><p><a href="https://the-algorithms.com/">The Algorithms</a></p><p><a href="https://github.com/TheAlgorithms">The Algorithms’s GitHub</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>决赛见！</title>
      <link href="/2021/11/01/%E5%86%B3%E8%B5%9B%E8%A7%81/"/>
      <url>/2021/11/01/%E5%86%B3%E8%B5%9B%E8%A7%81/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【Colab】基本操作【LeNet】【MNIST】训练测试</title>
      <link href="/2021/10/31/Colab+LeNet+MNIST/"/>
      <url>/2021/10/31/Colab+LeNet+MNIST/</url>
      
        <content type="html"><![CDATA[<p><a href="https://colab.research.google.com/notebooks/welcome.ipynb">Colab 官网初始界面</a></p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h1><p><a href="https://developer.nvidia.com/zh-cn/cuda-gpus">英伟达官网</a><br>谷歌将原来K80换成了T4<br><img src="https://img-blog.csdnimg.cn/7975074e2ece4cdc8be72e96851fd996.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="2-查看基本配置"><a href="#2-查看基本配置" class="headerlink" title="2.查看基本配置"></a>2.查看基本配置</h1><h3 id="2-1查看pytorch版本"><a href="#2-1查看pytorch版本" class="headerlink" title="2.1查看pytorch版本"></a>2.1查看pytorch版本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b08a271c94da4d0293ac0dbc8ff3cc25.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_13,color_FFFFFF,t_70,g_se,x_16"></p><h3 id="2-2查看是否可以使用cuda"><a href="#2-2查看是否可以使用cuda" class="headerlink" title="2.2查看是否可以使用cuda"></a>2.2查看是否可以使用cuda</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/cce0d37208584800922981b38136b11f.png"><br>修改-&gt;笔记本设置-&gt;GPU<br><img src="https://img-blog.csdnimg.cn/38bcb5ea6f724e1a8a120bd71614efcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_19,color_FFFFFF,t_70,g_se,x_16"></p><h3 id="2-3查看显卡配置"><a href="#2-3查看显卡配置" class="headerlink" title="2.3查看显卡配置"></a>2.3查看显卡配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line">//注意英文感叹号</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a222ea06ae0c44ce8f34592494dca1c3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="3-挂载"><a href="#3-挂载" class="headerlink" title="3.挂载"></a>3.挂载</h1><h3 id="31-挂载谷歌云盘"><a href="#31-挂载谷歌云盘" class="headerlink" title="31.挂载谷歌云盘"></a>31.挂载谷歌云盘</h3><p>Colab的运行原理实际上就是给你分配一台远程的带GPU的主机，所以它的原始路径不是你的谷歌云盘（也就是你的代码文件）所在的路径。所以第一步我们先要把谷歌云盘挂载带到那台远程主机上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&quot;/content/drive&quot;</span>)</span><br></pre></td></tr></table></figure><p>登录谷歌账号并将验证码粘到框中</p><h3 id="3-2更改运行目录"><a href="#3-2更改运行目录" class="headerlink" title="3.2更改运行目录"></a>3.2更改运行目录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;/content/drive/MyDrive/Colab Notebooks/LeNet_MNIST_train_test&quot;</span>)</span><br></pre></td></tr></table></figure><p>下面是我的目录结构<br><img src="https://img-blog.csdnimg.cn/a96be368c2ef4298af8e0fae94d4f61d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQVhETE1H,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="4-训练"><a href="#4-训练" class="headerlink" title="4.训练"></a>4.训练</h1><p>【LeNet】+【MNIST】</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>),</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        output = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">train_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    dataset=train_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_datasets = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">r&#x27;../data&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">test_dataloader = DataLoader(</span><br><span class="line">    dataset=test_datasets,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_datasets_size = <span class="built_in">len</span>(train_datasets)</span><br><span class="line">test_datasets_size = <span class="built_in">len</span>(test_datasets)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_datasets_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集数量为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_datasets_size))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">runing_mode = <span class="string">&quot;gpu&quot;</span> <span class="comment"># cpu,gpu, gpus</span></span><br><span class="line"><span class="keyword">if</span> runing_mode == <span class="string">&quot;gpu&quot;</span> <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cuda&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;use cpu&quot;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = LeNet()</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss_fn.to(device)</span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">epoch = <span class="number">10</span></span><br><span class="line">train_step, test_step = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;~~~~~~~~~~~~第&#123;&#125;轮训练开始~~~~~~~~~~~&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    start = time.time()</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">        output = model(imgs)</span><br><span class="line">        loss = loss_fn(output, targets)</span><br><span class="line"></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line"></span><br><span class="line">        train_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> train_step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;次训练，loss=&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(train_step, loss.item()))</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        test_loss, true_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            imgs, targets = imgs.to(device), targets.to(device)</span><br><span class="line">            output = model(imgs)</span><br><span class="line">            test_loss += loss_fn(output, targets)</span><br><span class="line">            true_num += (output.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;轮测试集上的loss:&#123;:.3f&#125;, 正确率为:&#123;:.3f&#125;%,耗时:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(test_step+<span class="number">1</span>, test_loss.item(), <span class="number">100</span> * true_num / test_datasets_size, end-start))</span><br><span class="line">    test_step += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>运行结果：<br>1.CPU<br><img src="https://img-blog.csdnimg.cn/14edcf10c0d446a189f4a6fc44fba1ce.png"><br>2.GPU<br><img src="https://img-blog.csdnimg.cn/f396f9c673a24d719516dd5abc055ba1.png"></p><h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5.Reference"></a>5.Reference</h1><p><a href="https://blog.csdn.net/u010881576/article/details/120919330">《Colab使用训练指南》 坚强的羊脂球</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>10月文章分享</title>
      <link href="/2021/10/30/10%E6%9C%88%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"/>
      <url>/2021/10/30/10%E6%9C%88%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="1-演讲"><a href="#1-演讲" class="headerlink" title="1.演讲"></a>1.演讲</h1><h2 id="1-1Steven-Chu：Life-is-too-short-to-go-through-it-without-caring-deeply-about-something"><a href="#1-1Steven-Chu：Life-is-too-short-to-go-through-it-without-caring-deeply-about-something" class="headerlink" title="1.1Steven Chu：Life is too short to go through it without caring deeply about something."></a>1.1Steven Chu：Life is too short to go through it without caring deeply about something.</h2><p><a href="https://news.harvard.edu/gazette/story/2009/06/u-s-energy-secretary-steven-chus-address-at-harvards-afternoon-exercises/">Stenven Chu in_Harvard Commencement 2009</a></p><p><a href="https://ruanyifeng.com/blog/2009/06/remarks_of_stenven_chu_in_harvard_commencement_2009.html">ruanyifeng’s blog:Remarks of Stenven Chu in harvard commencement</a></p><h2 id="1-2李彦宏：创新、跨界、开放的新工科人才"><a href="#1-2李彦宏：创新、跨界、开放的新工科人才" class="headerlink" title="1.2李彦宏：创新、跨界、开放的新工科人才"></a>1.2李彦宏：创新、跨界、开放的新工科人才</h2><p><a href="http://www.pku.org.cn/people/xyjy/1350143.htm">1987级校友李彦宏在北大新工科国际论坛上的演讲</a></p><h2 id="1-3丘成桐-中学数学教育"><a href="#1-3丘成桐-中学数学教育" class="headerlink" title="1.3丘成桐 中学数学教育"></a>1.3丘成桐 中学数学教育</h2><p><a href="https://blog.csdn.net/FnqTyr45/article/details/80490984">丘成桐：中国学生基础真的比欧美学生好吗？</a></p><p>ps：找了一些相同内容的文章，标题太刺眼，感谢这位博主的文章~</p><h1 id="2-人物"><a href="#2-人物" class="headerlink" title="2.人物"></a>2.人物</h1><h2 id="2-1-Klaus-Hasselmann：I-did-not-have-a-real-supervisor"><a href="#2-1-Klaus-Hasselmann：I-did-not-have-a-real-supervisor" class="headerlink" title="2.1 Klaus Hasselmann：I did not have a real supervisor"></a>2.1 Klaus Hasselmann：I did not have a real supervisor</h2><p><a href="https://www.aip.org/history-programs/niels-bohr-library/oral-histories/33645">Oral History Interviews about Klaus Hasselmann on February 15, 2006</a></p><h2 id="2-2-施一公-如何做一名优秀的博士生？"><a href="#2-2-施一公-如何做一名优秀的博士生？" class="headerlink" title="2.2 施一公 如何做一名优秀的博士生？"></a>2.2 施一公 如何做一名优秀的博士生？</h2><p><a href="http://blog.sciencenet.cn/blog-46212-484416.html">（一）时间的付出</a></p><p><a href="http://blog.sciencenet.cn/blog-46212-486270.html">（二）方法论的转变</a></p><h2 id="2-3-Matt-Might：10-easy-ways-to-fail-a-Ph-D"><a href="#2-3-Matt-Might：10-easy-ways-to-fail-a-Ph-D" class="headerlink" title="2.3 Matt Might：10 easy ways to fail a Ph.D."></a>2.3 Matt Might：10 easy ways to fail a Ph.D.</h2><p><a href="https://matt.might.net/articles/ways-to-fail-a-phd/">Matt Might：ways to fail a Ph.D.</a></p><h2 id="2-4-跟李沐学AI"><a href="#2-4-跟李沐学AI" class="headerlink" title="2.4 跟李沐学AI"></a>2.4 跟李沐学AI</h2><p><a href="https://www.bilibili.com/read/cv13335461/">李沐：用随机梯度下降来优化人生</a></p><p>沐神的b站：<a href="https://space.bilibili.com/1567748478">跟李沐学AI</a></p><h2 id="2-5-LShang001"><a href="#2-5-LShang001" class="headerlink" title="2.5 LShang001"></a>2.5 LShang001</h2><p>LShang001的b站：<a href="https://i0.hdslb.com/bfs/space/cb1c3ef50e22b6096fde67febe863494caefebad.png">LShang001</a></p><h2 id="2-6-稚晖君"><a href="#2-6-稚晖君" class="headerlink" title="2.6 稚晖君"></a>2.6 稚晖君</h2><p>稚晖君的b站：<a href="https://space.bilibili.com/20259914?from=search&seid=1336220716890113133&spm_id_from=333.337.0.0">稚晖君</a></p><p>稚晖君的Github：<a href="https://github.com/peng-zhihui">稚晖</a></p><h2 id="2-7-张焕晨-读博，你真的想好了吗？"><a href="#2-7-张焕晨-读博，你真的想好了吗？" class="headerlink" title="2.7 张焕晨 读博，你真的想好了吗？"></a>2.7 张焕晨 读博，你真的想好了吗？</h2><p><a href="https://zhuanlan.zhihu.com/p/372884253">张焕晨：读博，你真的想好了吗？</a></p><p>ps：根据个人需求有选择地阅读，尽量不要受到他人评论影响~</p><h1 id="3-前沿新闻"><a href="#3-前沿新闻" class="headerlink" title="3.前沿新闻"></a>3.前沿新闻</h1><h2 id="3-1-Ghost-Robotics-CEO-Jiren-Parikh：If-our-robot-had-tracks-on-it-instead-of-legs-nobody-would-be-paying-attention"><a href="#3-1-Ghost-Robotics-CEO-Jiren-Parikh：If-our-robot-had-tracks-on-it-instead-of-legs-nobody-would-be-paying-attention" class="headerlink" title="3.1 Ghost Robotics CEO Jiren Parikh：If our robot had tracks on it instead of legs, nobody would be paying attention."></a>3.1 Ghost Robotics CEO Jiren Parikh：If our robot had tracks on it instead of legs, nobody would be paying attention.</h2><p><a href="https://spectrum.ieee.org/ghost-robotics-armed-military-robots">Interview with Jiren Parikh, CEO of Ghost Robotics by IEEE Spectrum.</a></p><h2 id="3-2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）"><a href="#3-2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）" class="headerlink" title="3.2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）"></a>3.2中科院脑智卓越中心徐波、蒲慕明联合研究团队近期借助生物网络中发现的介观尺度自组织反向传播机制（Self-backpropagation，SBP）</h2><p><a href="https://www.science.org/doi/10.1126/sciadv.abh0146">Self-backpropagation of synaptic modifications elevates the efficiency of spiking and artificial neural networks</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>这篇博客的诞生</title>
      <link href="/2021/10/30/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
      <url>/2021/10/30/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_52034760/article/details/121047628">Hexo+Github搭建blog</a></p><p>这里为了不熟悉Markdown语法，挂上官方连接：<br><a href="https://markdown.com.cn/basic-syntax/">Markdown基本语法</a></p><p>02 Apr，2021&lt;<br>1.小白<br>2.不适应Shell<br>3.不了解Markdown及HTML</p><p>30 Oct，2021<br>1.逐渐适应Shell<br>2.Markdown基础语法<br>3.Git原理未了解<br>4.GitHub使用增多，Gist、论文源代码、开源项目（少）<br>5.SSH原理未了解<br>6.URL原理未了解<br>7.Github中的master暂未了解<br>8.默认主题</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
